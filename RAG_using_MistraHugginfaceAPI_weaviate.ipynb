{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "4164960c-193f-42bc-92c2-a088c2ba7974",
   "metadata": {},
   "outputs": [],
   "source": [
    "# !pip install weaviate-client langchain tiktoken pypdf rapidocr-onnxruntime"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "cb140e19-b3f2-4518-8efc-b3ab240b52dd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# !pip install protobuf==6.30.0 --upgrade"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "id": "684ae434-1afa-4584-a9af-ddcd45b009b7",
   "metadata": {},
   "outputs": [],
   "source": [
    "WEAVIATE_API_KEY=\"dDI1bG5rVkpudDY5QjVwZF9xcmliZjFEVEVDbGNBMk52Uk1EbjlSUnRvWG1qemVrL2ZiQVJUaXlUQmpnPV92MjAw\"\n",
    "WEAVIATE_URL=\"dub7a8xvs02atcecjtmbxw.c0.asia-southeast1.gcp.weaviate.cloud\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "id": "5a58474f-adf8-4a79-9c77-5328a840a777",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "True\n"
     ]
    }
   ],
   "source": [
    "from weaviate import Client\n",
    "\n",
    "from langchain_community.vectorstores import Weaviate\n",
    "from weaviate.classes.init import Auth\n",
    "\n",
    "import weaviate\n",
    "\n",
    "client = weaviate.connect_to_weaviate_cloud(\n",
    "    cluster_url=WEAVIATE_URL,\n",
    "    auth_credentials=Auth.api_key(WEAVIATE_API_KEY),\n",
    ")\n",
    "\n",
    "print(client.is_ready())  \n",
    "\n",
    "client.close() \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "id": "0daa8e9f-2fb5-4a7a-b916-95cd9084770b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "HuggingFace embedding model 'sentence-transformers/all-mpnet-base-v2' loaded successfully!\n"
     ]
    }
   ],
   "source": [
    "# specify embedding model (using huggingface sentence transformer)\n",
    "\n",
    "\n",
    "from langchain_huggingface import HuggingFaceEmbeddings\n",
    "\n",
    "embedding_model_name = \"sentence-transformers/all-mpnet-base-v2\"\n",
    "\n",
    "embedding = HuggingFaceEmbeddings(\n",
    "    model_name=embedding_model_name,\n",
    "    model_kwargs={'device': 'cpu'},\n",
    "    encode_kwargs={'normalize_embeddings': True}\n",
    ")\n",
    "\n",
    "print(f\"HuggingFace embedding model '{embedding_model_name}' loaded successfully!\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "id": "869f2549-8435-41da-adb2-556616dc9512",
   "metadata": {},
   "outputs": [],
   "source": [
    "# For load Pdf\n",
    "\n",
    "from langchain_community.document_loaders import PyPDFLoader\n",
    "loader = PyPDFLoader(\"rag.pdf\")\n",
    "\n",
    "pages = loader.load()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "id": "d8d34d66-69a3-49fe-bb58-573c83efa049",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Document(metadata={'producer': 'Skia/PDF m131 Google Docs Renderer', 'creator': 'PyPDF', 'creationdate': '', 'title': 'A Comprehensive Review of Retrieval-Augmented Generation (RAG): Key Challenges and Future Directions', 'source': 'rag.pdf', 'total_pages': 18, 'page': 0, 'page_label': '1'}, page_content='A Comprehensive Survey of Retrieval-Augmented Generation (RAG): Evolution, CurrentLandscapeandFutureDirections\\nShailjaGupta(CarnegieMellonUniversity, USA)RajeshRanjan(CarnegieMellonUniversity, USA)SuryaNarayanSingh(BITSindri, India)\\nAbstract\\nThis paper presents a comprehensive study of Retrieval-Augmented Generation (RAG), tracing itsevolution fromfoundational concepts to the current state of theart. RAGcombinesretrieval mechanismswith generative language modelstoenhancetheaccuracyof outputs, addressingkeylimitationsof LLMs.Thestudyexploresthebasicarchitectureof RAG, focusingonhowretrieval andgenerationareintegratedto handle knowledge-intensive tasks. Adetailed reviewof the significant technological advancements inRAG is provided, including key innovations in retrieval-augmented language models and applicationsacross various domains such as question-answering, summarization, and knowledge-based tasks.Recent research breakthroughs are discussed, highlighting novel methods for improving retrievalefficiency. Furthermore, the paper examines ongoing challenges such as scalability, bias, and ethicalconcerns in deployment. Future research directions are proposed, with a focus on improving therobustness of RAGmodels, expanding the scope of application of RAGmodels, andaddressingsocietalimplications. This survey aims to serve as a foundational resource for researchers and practitioners inunderstandingthepotential of RAGanditstrajectoryinthefieldof natural languageprocessing.\\nFigure1: TrendsinRAGcapturedfromrecent researchpapers\\nKeywords: Retrieval-Augmented Generation (RAG), InformationRetrieval, Natural LanguageProcessing(NLP), Artificial Intelligence(AI), MachineLearning(ML), LargeLanguageModel (LLM).'),\n",
       " Document(metadata={'producer': 'Skia/PDF m131 Google Docs Renderer', 'creator': 'PyPDF', 'creationdate': '', 'title': 'A Comprehensive Review of Retrieval-Augmented Generation (RAG): Key Challenges and Future Directions', 'source': 'rag.pdf', 'total_pages': 18, 'page': 1, 'page_label': '2'}, page_content=\"Introduction\\n1.1IntroductionofNatural LanguageGeneration(NLG)\\nNatural Language Processing (NLP) has become a pivotal domain within artificial intelligence (AI), withapplications ranging from simple text classification to more complex tasks such as summarization,machinetranslation, andquestionanswering. Aparticularlysignificant branchof NLPisNatural LanguageGeneration (NLG), which focuses on the production of human-like language from structured orunstructured data. NLG's goal is to enable machines to generate coherent, relevant, and context-awaretext, improvinginteractionsbetweenhumansandmachines(Gatt et. al. 2018). AsAI evolves, thedemandfor more contextually awareandfactuallygroundedgeneratedcontent hasincreased, bringingabout newchallengesandinnovationsinNLG.\\nTraditional NLG models, especially sequence-to-sequence architectures (Sutskever et al. 2014), haveexhibited significant advancements ingeneratingfluent andcoherent text. However, thesemodelstendtorely heavily on training data, often struggling when tasked with generating factually accurate orcontextually rich content for queries that require knowledge beyond theirtrainingset. Asaresult, modelslike GPT (Radford et al. 2019) or BERT-based (Devlin et al. 2019) text generators are prone tohallucinations, where they produceplausiblebut incorrect ornon-existent information(Ji et al. 2022). Thislimitation has prompted the exploration of hybrid models that combine retrieval mechanisms withgenerative capabilities to ensure both fluency and factual correctness in outputs. There has been asignificant rise in several research papers in this field and several new methods across the RAGcomponents have been proposed. Apart fromnew algorithms and methods, RAGhas also seen steepadoption across various applications. However, there is a gapinasufficient surveyof thisspacetrackingtheevolutionandrecent changesinthisspace. Thecurrent surveyintendstofill thisgap.\\n1.2OverviewofRetrieval-AugmentedGeneration(RAG)\\nRetrieval-Augmented Generation (RAG) is an emerging hybrid architecture designed to address thelimitations of pure generative models. RAG integrates two key components: (i) a retrieval mechanism,which retrieves relevant documents or information from an external knowledge source, and (ii) ageneration module, which processesthisinformationtogeneratehuman-liketext (Lewiset al. 2020). Thiscombination allows RAG models to not only generate fluent text but also ground their outputs inreal-world, up-to-datedata.\\nThe retrieval module in RAG typically leverages dense vector representations to identify relevantdocuments from large datasets, such as Wikipedia or proprietary databases. Once retrieved, thesedocuments are passed to the generative module, often built using transformer-based architectures, togenerate responses grounded in the retrieved knowledge. This methodology helps mitigate thehallucination problemand ensures that the generated text is more factual and contextually appropriate(Thakur et al. 2021). Over the period, RAGmodels have seen applicationsinvariousdomains, includingopen-domain question answering (Karpukhin et al., 2020), conversational agents (Liu et al. 2021), andpersonalizedrecommendations.\"),\n",
       " Document(metadata={'producer': 'Skia/PDF m131 Google Docs Renderer', 'creator': 'PyPDF', 'creationdate': '', 'title': 'A Comprehensive Review of Retrieval-Augmented Generation (RAG): Key Challenges and Future Directions', 'source': 'rag.pdf', 'total_pages': 18, 'page': 2, 'page_label': '3'}, page_content='Figure2: Abasicflowof theRAGsystemalongwithitscomponent\\n1.3EvolutionofHybridModelsinNLP\\nBefore the introduction of RAG, NLPmodelsprimarilyreliedoneitherretrieval orgenerationapproaches,each with its own set of advantages and limitations. Retrieval-based systems, such as traditionalinformation retrieval engines (Salton et al., 1975), efficiently provided relevant documents or snippets inresponse to a query but could not synthesize new information or present the results in a coherentnarrative. On the other hand, purely generative models, which became popular with the rise oftransformer architectures (Vaswani et al. 2017), offered fluency and creativity but often lacked factualaccuracy.\\nThe development of hybrid systems combining retrieval and generation began to gain momentumasresearchers recognizedthecomplementarystrengthsof bothapproaches. Earlyeffortsinhybridmodelingcan be traced back to works like DrQA(Chen et al. 2017), which employed retrieval techniques to fetchrelevant documents for question-answering tasks. However, the generative component in such systemswas minimal, often limited to selecting text directlyfromtheretrieveddocuments. Similarly, inmodelslikeInformationRetrieval (Dai et al. 2019), retrieval wastreatedasdistinct, independent components.\\nThe real innovation came with the realization that retrieval and generation could be tightly integrated.Models like REALM (Guu et al., 2020) represented a key milestone, as they trained the retrieval andgenerative components jointly, enabling better alignment between the retrieved information and thegenerated output. RAG (Lewis et al. 2020) further extended this paradigm by using dense passageretrieval (Karpukhin et al., 2020) to fetch relevant documents and transformers like BART(Lewis et al.,2020) for a generation. This architecture provided a more seamless integration of retrieval andgeneration, allowingthemodel toansweropen-endedquestionswithbothfluencyandfactual grounding.\\n1.4ImportanceofFactuallyGroundedLanguageGeneration\\nOne of the main motivations for developing RAG is the increasing demand for factually accurate,contextually relevant, and up-to-date generated content. Inmanyapplications, suchascustomerservice,medical diagnostics, or legal advisory systems, the need for reliable and grounded responses isparamount. Generative models that produce hallucinated or inaccurate information can lead to seriousconsequences, suchasspreadingmisinformationorprovidingincorrect advice(Ji et al. 2022).'),\n",
       " Document(metadata={'producer': 'Skia/PDF m131 Google Docs Renderer', 'creator': 'PyPDF', 'creationdate': '', 'title': 'A Comprehensive Review of Retrieval-Augmented Generation (RAG): Key Challenges and Future Directions', 'source': 'rag.pdf', 'total_pages': 18, 'page': 3, 'page_label': '4'}, page_content=\"RAG models directly address these concerns by grounding their generative process in external,up-to-date knowledge sources. This groundingimprovesthefactual accuracyof theoutput andenhancesthe relevance of responses by incorporating real-world data that is directly tiedtothequery. Additionally,RAGmodels are less likely to propagate biases present in static training data, astheycanretrievemorediverseandbalancedinformationfromexternal sources\\n1.5ApplicationsofRAGModels\\nRAG models have been applied across a wide array of domains where factual accuracy and contextualunderstanding are critical. One of themost prominent applicationsisinopen-domainquestionanswering,where the model must generate answers based on a wide range of topics. RAGhas proven effective inimproving answer accuracy byretrievingrelevant informationandthengeneratingresponsesgroundedinthat data (Izacard et. al. 2021). Models like Dense PassageRetrieval (DPR)(Karpukhinet al., 2020)andFusion-in-Decoder(Izacardet. al. 2021)havebeenusedtogreat effect inthiscontext, showingsignificantimprovementsovertraditional generativeorretrieval-onlymodels.\\nIn conversational AI, RAGmodels have enhanced the capabilities of dialogue systems by ensuring thatresponses are both coherent and grounded in factual information (Roller et al., 2020). For example,chatbots used in customer service can benefit fromRAG's ability to retrievespecificdetailsfromproductdatabasesordocumentation, leadingtomoreaccurateanduseful responsesforend-users.\\nOther applications include medical diagnosis systems, where RAGcan retrieve and integrate the latestresearch findings or patient-specific data togenerateaccuratediagnosticsuggestions, andlegal advisorysystems, where the model can retrieve relevant case law or statutes to provide legally sound advice.Furthermore, RAGhasfoundapplicationsinpersonalizedrecommendationsystems, whereit canretrieveuserpreferencesorpast interactionsandgeneratepersonalizedsuggestions.\\n1.6ChallengesandLimitationsofRAG\\nDespite the promise of RAGmodels, several challenges need attention. The retrieval mechanism, whilepowerful, can still struggle with retrieving the most relevant documents, particularly when dealing withambiguous queries or niche knowledge domains. The reliance on dense vectorrepresentations, suchasthose used in DPR, can sometimes lead to irrelevant or off-topic documents being retrieved. Efforts torefine retrieval techniques, including the incorporation of more sophisticated query expansion andcontextual disambiguation, are needed to improve performance in these areas. The integration betweenretrieval and generation, while seamless in theory, can sometimes fail in practice. For instance, thegenerative module may not always effectively incorporate the retrieved information into its responses,leading to inconsistencies or incoherence between the retrieved facts and the generated text. Researchinto better alignment mechanisms, such as improved attention models or hierarchical fusion techniques,may help alleviate these issues (Izacard et. al. 2021). Additionally, the computational overhead of RAGmodels is a concern, as they require both a retrieval and a generation step for each query. This dualprocess can be resource-intensive, particularly for large-scale applications (Borgeaud et al. 2021).Techniques such as model pruning (Han et al. 2015) or knowledge distillation (Sanh et al., 2019) mayoffer ways to reduce the computational burden without sacrificing performance. Finally, there are ethicalconcerns associated with the deployment of RAGmodels, particularly in termsof biasandtransparency.Biases in AI and LLM have been a well-researched and evolving field with researchers identifyingdifferent types of biases not limited to Gender, socio-economic class, or even educational background(Gupta et. al. 2024; Ranjan et. al., 2024). While RAG has the potential to reduce biases by retrievingmore balanced information, there is still the risk of amplifying biases present in the retrieved sources\"),\n",
       " Document(metadata={'producer': 'Skia/PDF m131 Google Docs Renderer', 'creator': 'PyPDF', 'creationdate': '', 'title': 'A Comprehensive Review of Retrieval-Augmented Generation (RAG): Key Challenges and Future Directions', 'source': 'rag.pdf', 'total_pages': 18, 'page': 4, 'page_label': '5'}, page_content=\"(Binns, 2018). Furthermore, ensuring transparency in how retrieval results are selected and used ingenerationiscrucial formaintainingtrust inthesesystems.\\n1.7ScopeoftheSurvey\\nThis paper aims to provide a comprehensive survey of RAG models, covering their evolution, keyarchitectural components, recent research in this area, current challenges and limitations of RAG, andfutureresearchdirection.\\n2:CoreComponentsandArchitectural OverviewofRAGSystems\\n2.1OverviewofRAGModels\\nRetrieval-augmented generation (RAG) is an advanced hybrid model architecture that augments naturallanguage generation (NLG) with external retrieval mechanisms to enhance themodel'sknowledgebase.Traditional large language models (LLMs) such as GPT-3 and BERT, which are pre-trained on vastcorpora, rely entirely on their internal representations of knowledge, making themsusceptible to issueslike hallucinations—where the models generate plausible but incorrect information. Thesemodelscannotefficiently update their knowledge bases without retraining, making them less practical for dynamic,knowledge-intensive tasks like open-domain question answering and fact verification (Brown, T., et al.2020). Toovercometheselimitations, thepaper(Lewiset al. 2020)proposedtheRAGarchitecture, whichretrievesreal-time, relevant external documentstogroundthegeneratedtext infactual information.\\nTheRAGmodel incorporatestwokeycomponents:\\n1. Retriever: This retrieves the most relevant documents froma corpus using techniques such asdensepassageretrieval (DPR)(Karpukhinet. al. 2020)ortraditional BM25algorithms.2. Generator: It synthesizes the retrieved documents into coherent, contextually relevantresponses.\\nRAG’s strength lies in its ability to leverage external knowledge dynamically, allowing it to outperformgenerative models like GPT-3andknowledge-groundedsystemslikeBERT, whichrelyonstaticdatasets.In open-domain question answering, RAG has been demonstrated to be highly effective, consistentlyretrievingrelevant informationandimprovingthefactual accuracyof thegeneratedresponses(Guu, K., etal. 2020). In addition to knowledge retrieval, RAGmodels excel at updating knowledgebases. Sincethemodel fetches external documents for each query, it requires no retraining to incorporate the latestinformation. This flexibility makes RAG models particularly suitable for domains where information isconstantly evolving, such as medical research, financial news, and legal proceedings. Furthermore,studies have shown that RAGmodels achieve superior results in a varietyof knowledge-intensivetasks,includingdocument summarizationand, knowledge-groundeddialogues\\n2.2RetrieverMechanismsinRAGSystems\\nThe retriever in RAG systems is essential for fetching relevant documents from an external corpus.Effective retrieval ensures that the model's output is grounded in accurate information. Several retrievalmechanisms are commonly used, ranging from traditional methods like BM25 to more sophisticatedtechniqueslikeDensePassageRetrieval (DPR).\"),\n",
       " Document(metadata={'producer': 'Skia/PDF m131 Google Docs Renderer', 'creator': 'PyPDF', 'creationdate': '', 'title': 'A Comprehensive Review of Retrieval-Augmented Generation (RAG): Key Challenges and Future Directions', 'source': 'rag.pdf', 'total_pages': 18, 'page': 5, 'page_label': '6'}, page_content=\"2.2.1BM25\\nBM25 is a well-established informationretrieval algorithmthat usesthetermfrequency-inversedocumentfrequency (TF-IDF) to rank documents according to relevance. Despite being a classical method, BM25remains a strong baseline for many modern retrieval systems, including those used in RAG models.BM25 calculates therelevancescoreof adocument basedonhowfrequentlyaquerytermappearsinthedocument while adjusting for the document's length and the frequency of the termacross the corpus(Robertson et. al. 2009). WhileBM25iseffectiveforkeywordmatching, it haslimitationsinunderstandingsemantic meaning. For example, BM25 cannot capture the relationships between words and tends toperform poorly on more complex, natural language queries that require an understanding of context.Despite this limitation, BM25 is still widely used because of itssimplicityandefficiency. BM25iseffectivefor tasks involvingsimpler, keyword-basedqueries, althoughmoremodernretrieval modelslikeDPRtendtooutperformit insemanticallycomplextasks.\\n2.2.2DensePassageRetrieval (DPR)\\nDense Passage Retrieval (DPR), introduced by Karpukhin et al. (2020), represents a more modernapproach to information retrieval. It uses a dense vector space in which both the query and thedocuments are encoded into high-dimensional vectors. DPR employs a bi-encoder architecture, wherethe query and documents are encoded separately, allowing for efficient nearest-neighbor search (Xionget. al. 2020). Unlike BM25, DPR excels at capturing semantic similarity between the query anddocuments, making it highly effective for open-domain question-answering tasks. The strength of DPRlies in its ability to retrieve relevant information based on semantic meaning rather than keywordmatching. By training the retriever on a large corpus of question-answer pairs, DPRcan finddocumentsthat are contextually related to the query, even when the query and the document do not share exactterms. Recent research has further improved DPRbyintegratingit withpre-trainedlanguagemodelsandanexampleisLLMadaptedforthedenseRetrievAl approach(Li et. al. 2023)\\n2.2.3REALM(Retrieval-AugmentedLanguageModel)\\nAnother significant advancement in retrieval mechanisms for RAGmodels is REALM(Guu et al. (2020).REALMintegrates retrieval into the language model's pre-training process, ensuring that the retriever isoptimized alongside the generator for downstreamtasks. ThekeyinnovationinREALMisthat it learnstoretrieve documents that improve the model’s performance on specific tasks, suchasquestionansweringor document summarization. During training, REALM updates both the retriever and the generator,ensuring that the retrieval process is optimized for the generation task. REALM’s retriever is trained toidentify documents that are not only relevant to the query but also helpful for generating accurate andcoherent responses. As a result, REALM significantly improves the quality of generated responses,particularly in tasks that require external knowledge. Recent studies have demonstrated that REALMoutperforms both BM25 and DPR in certain knowledge-intensive tasks, particularly when retrieval istightlycoupledwithgeneration.\\nThe core of RAG lies in the quality of retrieved passages, but many current methods rely onsimilarity-based retrieval (Mallen et al. 2022). Self-RAG (Asai et al. 2023b), and REPLUG (Shi et al.,2023) have advanced by leveraging LLMs to enhance retrieval capabilities, achieving more adaptiveretrieval. After initial retrieval, cross-encoder models are used to re-rank the retrieved results by jointlyencoding the query and each retrieved document to compute relevance scores. These models providemore context-aware retrieval at the cost of higher computational overhead. Pointwise and PairwiseRanking, often based on Learning-to-Rank (LTR) algorithms, are used to assign relevance scores to\"),\n",
       " Document(metadata={'producer': 'Skia/PDF m131 Google Docs Renderer', 'creator': 'PyPDF', 'creationdate': '', 'title': 'A Comprehensive Review of Retrieval-Augmented Generation (RAG): Key Challenges and Future Directions', 'source': 'rag.pdf', 'total_pages': 18, 'page': 6, 'page_label': '7'}, page_content=\"retrieved documents, either independently (pointwise) or by comparing document pairs (pairwise). RAGsystems utilizeself-attentionwithintheLLMtomanagecontext andrelevanceacrossdifferent partsof theinput and retrieved text. Cross-attentionmechanismsareusedwhenintegratingretrievedinformationintothe generative model, ensuring that the most relevant pieces of information are emphasized duringgeneration.\\n2.3GeneratorMechanismsinRAGSystems\\nIn Retrieval-Augmented Generation (RAG) systems, the generator mechanism plays a crucial role inproducing the final output by integrating retrieved information with the input query. After the retrievalcomponent pulls relevant knowledge fromexternal sources, the generator synthesizes this informationinto coherent, contextually appropriate responses. The Large Language Model (LLM) serves as thebackbone of the generator, which ensures the generated text is fluent, accurate, and aligned with theoriginal query.\\n2.3.1T5(Text-to-TextTransferTransformer)\\nT5 (Text-to-Text Transfer Transformer) (Raffel et al. 2020) is one of the most commonlyusedmodelsforgeneration tasks in RAGsystems. T5isversatileinitsapproach, framingeveryNLPtaskasatext-to-texttask. This uniform framework allows T5 to be fine-tuned for a wide range of tasks, includingquestion-answering, summarization, and dialogue generation. By integrating retrieval with generation,T5-based RAG models have been shown to outperformtraditional generative models like GPT-3 andBART on several benchmarks, including the Natural Questions dataset and the TriviaQA dataset.Moreover, T5's ability to handle complex multi-task learning makes it a popular choice for RAGsystemsthat needtotackleadiverserangeof knowledge-intensivetasks.\\n2.3.2BARTBART(Bidirectional andAuto-RegressiveTransformer), introducedbyLewiset al. (2020), isanotherprominent generativemodel usedinRAGsystems. BARTisparticularlywell-suitedfortasksinvolvingtextgenerationfromnoisyinputs, suchassummarizationandopen-domainquestionanswering. Asadenoisingautoencoder, BARTcanreconstruct corruptedtext sequences, makingit robust fortasksthatrequirethegenerationof coherent, factual outputsfromincompleteornoisydata. WhenpairedwitharetrieverinaRAGsystem, BARThasbeenshowntoimprovethefactual accuracyof generatedtext bygroundingit inexternal knowledge. Studieshavedemonstratedthat BART-basedRAGmodelsachievestate-of-the-art resultsinvariousknowledge-intensivetasks, includingdialoguegenerationandnewssummarization.\\n3. Retrieval-AugmentedGenerationModelsAcrossDifferentModalities\\n3.1 Text-Based RAG Models: Text-based RAG models represent the most mature and widelyresearched category. These models leverage textual data for both retrieval and generation tasks,enabling applications such as question-answering, summarization, and conversational agents.Transformer architectures, such as BERT (Devlin et al., 2019) and T5 (Raffel et al., 2020), arefoundational in text-based RAG models. These models utilize self-attention mechanisms to capturecontextual relationships within text, which enhances both retrieval accuracy and generation fluency.Dense retrieval models, such as those using dense embeddings fromBERT, offer superior performancecompared to traditional sparse methods like TF-IDF. Dense retrievers (Karpukhin et al. 2020), leveragedense representations to retrieve relevant documents more effectively. Recent advancements focus onintegrating retrieval and generation into a single training pipeline. REALM (Guu et al., 2020) is an\"),\n",
       " Document(metadata={'producer': 'Skia/PDF m131 Google Docs Renderer', 'creator': 'PyPDF', 'creationdate': '', 'title': 'A Comprehensive Review of Retrieval-Augmented Generation (RAG): Key Challenges and Future Directions', 'source': 'rag.pdf', 'total_pages': 18, 'page': 7, 'page_label': '8'}, page_content='example of such anend-to-endmodel that jointlyoptimizesretrieval andgenerationprocesses, improvingoverall taskperformance.\\n3.2 Audio-BasedRAGModels: Audio-based RAGmodels extend the principles of retrieval-augmentedgeneration to the audio modality, enablingapplicationssuchasspeechrecognition, audiosummarization,and conversational agents in voice interfaces. Audiodataisoftenrepresentedusingembeddingsderivedfrompre-trained models like Wav2Vec 2.0 (Baevski et al., 2020). These embeddings serve as input toretrieval andgenerationcomponents, enablingthemodel tohandleaudiodataeffectively.\\n3.3 Video-Based RAG Models: Video-based RAG models incorporate both visual and textualinformation to enhance performance in tasks such as video understanding, captioning, and retrieval.Video data is represented using embeddings from models like I3D (Xie et. al. 2017) or TimeSformer(Bertasius et al. 2021). These embeddings capture temporal and spatial features essential for effectiveretrieval andgeneration.\\n3.4 Multimodal RAG Models: Multimodal RAG models integrate data frommultiple modalities—text,audio, video, and images—to provide a more holistic approach to retrieval andgenerationtasks. Modelslike Flamingo (Alayrac et al., 2022) integrate multiple modalities into a unified framework, enablingsimultaneous processing of text, images, and videos. Techniques for cross-modal retrieval involveretrievingrelevant informationacrossdifferent modalities(Li. et. al. 2023).\\nMultimodal capabilities enhance the versatility and efficiency of RAG across various applications.”Retrieval as generation” (Wang et. al. 2024) extends the Retrieval-Augmented Generation (RAG)framework tomultimodal applicationsbyincorporatingtext-to-imageandimage-to-text retrieval. Utilizingalarge dataset of pairedimagesandtext descriptions, thesystemacceleratesimagegenerationwhenuserqueries align with stored text descriptions (\"retrieval as generation\"). The image-to-text functionalityallowsuserstoengageindiscussionsbasedoninput images.\\nFigure3: Timelineof theevolutionof theRAGsystemanditscomponents'),\n",
       " Document(metadata={'producer': 'Skia/PDF m131 Google Docs Renderer', 'creator': 'PyPDF', 'creationdate': '', 'title': 'A Comprehensive Review of Retrieval-Augmented Generation (RAG): Key Challenges and Future Directions', 'source': 'rag.pdf', 'total_pages': 18, 'page': 8, 'page_label': '9'}, page_content='4. RecentAdvancementinthefield:\\nThere has been significant advancement in this field and this section intendstocapturekeyfindingsof afewimportant recent papers. Anovel agenticRetrieval-AugmentedGeneration(RAG)framework(Ravuruet. al. 2024) employs a hierarchical, multi-agent architecturewherespecializedsub-agents, usingsmallerpre-trained language models (SLMs), are fine-tuned for specific time series tasks. The master agentdelegates tasks to these sub-agents, who retrieve relevant prompts fromasharedknowledgerepository.In this modular, multi-agent approach, the authors achieve state-of-the-art performance demonstratingimproved flexibility and effectiveness over task-specificmethodsintimeseriesanalysis. RULE(Xiaet. al.2024), a multimodal Retrieval-Augmented Generation (RAG) framework designed to improve thefactuality of medical Vision-Language Models (Med-LVLM), addresses challenges in medical RAG byintroducing a calibrated selection strategy to control factuality risk, and, by developing a preferenceoptimization strategy to balance the model’s intrinsic knowledge with retrieved contexts, proving itseffectiveness in enhancing factual accuracy in Med-LVLM systems. METRAG (Gan et. al. 2024), amulti-layered, thoughts-enhanced retrieval-augmented generation framework, integratesLLMsupervisionto generate utility-oriented thoughts and combines document similarity with utility for improvedperformance. It also incorporates a task-adaptive summarizer to produce compact thoughts. Using themulti-layered thoughts from these stages, an LLM generates knowledge-augmented content,demonstrating superior performance on knowledge-intensive tasks compared to traditional approaches.Distractordocument is\\nFigure4: EvolvingTrendsinRAGcapturedfromresearchpapers'),\n",
       " Document(metadata={'producer': 'Skia/PDF m131 Google Docs Renderer', 'creator': 'PyPDF', 'creationdate': '', 'title': 'A Comprehensive Review of Retrieval-Augmented Generation (RAG): Key Challenges and Future Directions', 'source': 'rag.pdf', 'total_pages': 18, 'page': 9, 'page_label': '10'}, page_content=\"one of the key traits of Retrieval AugmentedFine-Tuning(RAFT)(Zhanget. al. 2024)wherethemodel istrained to disregard irrelevant, distractor documents and instead cite directly fromrelevant sources. Thisprocess, combined with a chain-of-thought reasoning style, enhances themodel'sreasoningcapabilities.RAFT demonstrates consistent performance improvements in domain-specific RAG tasks, includingPubMed, HotpotQA, and Gorilla datasets, serving as a post-training enhancement for LLMs. FILCO(Wang et. al. 2023) , a method designed toenhancethequalityof context providedtogenerativemodelsin tasks like open-domain question answering and fact verification, addresses issues of over- orunder-relianceonretrievedpassages, whichcanleadtoproblemssuchashallucinationsinthegeneratedoutputs. The method improves context quality by identifying useful context through lexical andinformation-theoretic approaches and training context filtering models to refine retrieved contexts duringtest time. ReflectionTokenisakeyattributeof Self-reflectiveRetrieval Augmented-Generation(Self-RAG)(Asai et. al. 2023), anovel frameworkdesignedtoimprovethefactual accuracyof largelanguagemodels(LLMs) by combining retrieval with self-reflection. Unlike traditional methodsthat retrieveandincorporatea fixed number of passages, Self-RAGadaptively retrievesrelevant passagesandusesreflectiontokensto evaluate and refine its responses, allowing the model to adjust its behavior according to task-specificneeds and has shown superior performance in open-domain question-answering, reasoning, factverification, and long-formgenerationtasks. Intelligenceandeffectivenessof RAGaredependent alot onthe quality of retrieval and more meta-data understanding of the repository would enhance theeffectiveness of the RAGsystem. Anovel data-centric Retrieval-Augmented Generation (RAG)workflowadvances beyond the traditional retrieve-then-read mode and employs aprepare-then-rewrite-then-retrieve-then-read framework, enhancing LLMs by integrating contextuallyrelevant, time-critical, or domain-specific information. Key innovations include generating metadata,synthetic Questions and Answers (QA), and introducing the Meta Knowledge Summary (MKSummary)for clusters of documents (Mombaerts et. al. 2024). A recent paper introduces CommunityKG-RAG(Chang et. al. 2024), a zero-shot framework that integrates community structures within KnowledgeGraphs (KGs) into Retrieval-Augmented Generation (RAG) systems. This approach enhances theaccuracy and contextual relevance of fact-checking by utilizing multi-hop connections within KGs,outperforming traditional methods without requiring additional domain-specific training. The RAPTORmodel (Sarthi et. al. 2024) introduces a hierarchical approach to retrieval-augmented language models,addressing limitations in traditional methods that retrieve only short, contiguous text chunks. RAPTORforms a summary tree to retrieve information at varying abstraction levels by recursively embedding,clustering, and summarizing text. Experiments demonstrate RAPTOR’s superior performance, especiallyin question-answering tasks requiring complex reasoning. When paired with GPT-4, RAPTORimprovesaccuracyontheQuALITYbenchmarkby20%.\\nThis advancement in RAGfurtherprovestheutilityof theRAGsystemhoweverrecent LLMlaunchesthatsupport long-termcontext havesignificantlyshownimprovedperformance. Arecent study(Li et. al. 2024)compared the efficiency of Retrieval Augmented Generation (RAG) and long-context (LC) LargeLanguage Models (LLMs), such as Gemini-1.5 and GPT-4. While LC models outperform RAG whenadequately resourced, RAG's cost-efficiency remains advantageous. To balance performance and cost,the paper introduces Self-Route. This method dynamically directs queries to either RAGorLCbasedonmodel self-reflection, optimizing both computation cost and performance. This study offers valuableinsights into the optimal application of RAGand LCin handling long-context tasks. Nguyen et. al., 2024introduce SFR-RAG, a small but highly efficient Retrieval AugmentedGeneration(RAG)model, whichisdesigned to enhance the integration of external contextual information into Large Language Models(LLMs) while minimizing hallucinations. LA-RAG (Li et. al., 2024), a novel Retrieval-AugmentedGeneration (RAG) paradigm designed to enhance Automatic Speech Recognition (ASR) in largelanguage models (LLMs). One of the key benefits of LA-RAG is its ability to leverage fine-grainedtoken-level speech data stores alongside a speech-to-speech retrieval mechanism, improving ASR\"),\n",
       " Document(metadata={'producer': 'Skia/PDF m131 Google Docs Renderer', 'creator': 'PyPDF', 'creationdate': '', 'title': 'A Comprehensive Review of Retrieval-Augmented Generation (RAG): Key Challenges and Future Directions', 'source': 'rag.pdf', 'total_pages': 18, 'page': 10, 'page_label': '11'}, page_content=\"accuracy by incorporating LLMin-context learning (ICL). The studyfocusesondatasetsof Mandarinandvarious Chinese dialects, demonstrating significant accuracy improvements, particularly in managingaccent variations, which have historically been a challenge for existing speech encoders. The findingshighlight LA-RAG’s potential to advance ASR technology, offering a more robust solution for diverseacoustic conditions. Large Language Models (LLMs) face challenges in AI legal and policy contextsdueto outdated knowledge and hallucinations. HyPA-RAG(Kalra et. al., 2024), aHybridParameter-AdaptiveRetrieval-Augmented Generation system, improves accuracy by using adaptive parameter tuning andhybrid retrieval strategies. Tested on NYC Local Law144 (LL144), HyPA-RAGdemonstrates enhancedcorrectness and contextual precision, addressing the complexities of legal texts. MemoRAG(Qianet. al.,2024) introduces a novel Retrieval-Augmented Generation (RAG) paradigmdesigned to overcome thelimitations of traditional RAG systems in handling ambiguous or unstructured knowledge. MemoRAG’sdual-system architecture utilizes a lightweight long-range LLM to generate draft answers and guideretrieval tools, while a more powerful LLMrefines the final output. This framework, optimized for bettercluing and memory capacity, significantly outperforms conventional RAG models across both complexand straightforward tasks. NLLB-E5 (Acharya et. al., 2024) introduces a scalable multilingual retrievalmodel aimed at addressing the challenges faced in supporting multiple languages, particularlylow-resource languages like Indiclanguages. ByleveragingtheNLLBencoderandadistillationapproachfromtheE5multilingual retriever, NLLB-E5enableszero-shot retrieval acrosslanguageswithout theneedfor multilingual training data. Evaluations on benchmarks such as Hindi-BEIR showcase its robustperformance, highlighting task-specific challenges and advancing multilingual information access forglobal inclusivity.\\n5. CurrentChallenges andLimitationsinRetrieval-AugmentedGeneration(RAG):\\nThissectionintendstohighlight thecurrent challengesandlimitationsof RAGconsideringthecurrentlandscapeof thesystemandthiswouldshapethefutureresearchdirectionsinthefield.\\nScalability and Efficiency: One of the primary challenges for RAG models is scalability. As retrievalcomponentsrelyonexternal databases, handlingvast anddynamicallygrowingdatasetsrequiresefficientretrieval algorithms. High computational costs and memory requirements also make it difficult to deployRAGmodelsinreal-timeorresource-constrainedenvironments(Shi et al. 2023), (Asai et al. 2023b).\\nRetrieval Quality andRelevance: Ensuring the quality andrelevanceof retrieveddocumentsremainsasignificant concern. Retrieval models can sometimes return irrelevant or outdated information, whichnegatively affects the accuracy of the generated output. Improving retrieval precision, especially forlong-formcontent generation, remainsanactiveareaof research(Mallenet al. 2022), (Shi et al. 2023).\\nBias and Fairness: Similar to other machine learning models, RAG systems can exhibit bias due tobiases present in the retrieved datasets. Retrieval-based models may amplifyharmful biasesinretrievedknowledge, leading to biased outputs in a generation. Developing bias mitigation techniquesforretrievalandgenerationintandemisanongoingchallenge.\\nCoherence: RAG models often struggle with integrating the retrieved knowledge into coherent,contextually relevant text. The alignment between retrieved passages and the generationmodel'soutputis not always seamless, leading to inconsistencies or factual hallucinations in the final response(Ji et al.2022).\"),\n",
       " Document(metadata={'producer': 'Skia/PDF m131 Google Docs Renderer', 'creator': 'PyPDF', 'creationdate': '', 'title': 'A Comprehensive Review of Retrieval-Augmented Generation (RAG): Key Challenges and Future Directions', 'source': 'rag.pdf', 'total_pages': 18, 'page': 11, 'page_label': '12'}, page_content='Interpretability and Transparency: Like many AI systems, RAG models are often treated as blackboxes, with limited transparency in how retrieval influences generation. Improving the interpretability ofthesemodelsiscrucial tofosteringtrust, especiallyincritical applications(Rolleret al. 2020).\\n6. FutureResearchDirectionsforRetrieval-AugmentedGeneration(RAG)\\nRetrieval-augmented generation (RAG) represents a significant advancement in natural languageprocessing and related fields by combining retrieval and generative mechanisms. This section exploreskeyareasforfutureresearch, highlightingthepotential forinnovationandimprovement inRAGsystems.\\n6.1 Enhancing Multimodal Integration: The integration of text, image, audio, and video data in RAGmodels remains an evolving challenge. Future research should focus on improving multimodal fusiontechniques to enable seamless interaction between different data types. This includes developingadvanced methods for aligning and synthesizing information across modalities. Recent works (Chen et.al. 2022), (Yasunaga et. al. 2022), (Zhu et. al. 2024) have explored multimodal learning, but furtherinnovations are needed to enhance the coherence andcontextualityof multimodal outputs.Researchintocross-modal retrieval aims to improve the ability of RAGsystems to retrieve relevant information acrossdifferent modalities. For example, combining text-based queries with image or video content retrievalcould enhance applications such as visual question answering and multimedia search. This is anotherfuturedirectiontoexploreforRAGrelatedresearch.\\n6.2 Scaling and Efficiency: As RAG models are deployed in increasingly large-scale applications,scalability becomes a critical concern. Research should focus on developing methods toefficientlyscaleretrieval and generation processes without compromising performance. Techniques such as distributedcomputing and efficient indexing methods are essential for handling large datasets. Improving theefficiency of RAG models involves optimizing both retrieval and generation components to reducecomputational resourcesandlatency.\\n6.3 Personalization and Adaptation: Future RAG models should focus on personalizing retrievalprocesses to cater to individual user preferences and contexts. This involves developing techniques toadapt retrieval strategies based on user history, behaviour, and preferences. Enhancing the contextualadaptation of RAGmodels by deeper understandingof thecontext andsentimentsof query(Guptaet. al.2024) and the repository of ducments is crucial for improving the relevance of generated responses.Research should explore methods for dynamic adjustment of retrieval and generation processes basedontheevolvingcontext of interactions. Thisincludesincorporatinguserfeedbackandcontextual cuesintotheRAGpipeline.\\n6.4 Ethical andPrivacyConsiderations:Addressingbiases(Shresthaet. al. 2024), (Guptaet. al. 2024)in general and specifics to RAG models is a critical area for future research. As RAG systems aredeployed in diverse applications, ensuring fairness and mitigating biases in retrieved and generatedcontent is essential. Future RAG research should focus on privacy-preserving techniques to protectsensitive information during retrieval and generation. This includes developing methods for secure datahandling and privacy-aware retrieval strategies. Interpretability of model is also a critical area to focusuponasapart of ongoingresearchinimprovingRAG.\\n6.5 Cross-Lingual and Low-Resource Languages: Expanding RAG technology to support multiplelanguages ( Chirkova et. al. 2024), especially low-resource languages, is a promising direction. Future'),\n",
       " Document(metadata={'producer': 'Skia/PDF m131 Google Docs Renderer', 'creator': 'PyPDF', 'creationdate': '', 'title': 'A Comprehensive Review of Retrieval-Augmented Generation (RAG): Key Challenges and Future Directions', 'source': 'rag.pdf', 'total_pages': 18, 'page': 12, 'page_label': '13'}, page_content=\"research should aimtoimprovecross-lingual retrieval andgenerationcapabilitiestoprovideaccurateandrelevant results across different languages. Enhancing RAG models to effectively support low-resourcelanguages involves developing methods to retrieve and generate content with limited training data.Research should focus on techniques for transfer learning and data augmentation to improveperformanceinunderrepresentedlanguages.\\n6.6 Advanced Retrieval Mechanisms: Future RAG research should explore dynamic retrievalmechanisms that adapt to changing query patterns and content requirements. This includes developingmodels that can dynamically update theirretrieval strategiesbasedonnewinformationandevolvinguserneeds. Investigating hybrid retrieval approaches that combine various retrieval strategies, suchasdenseand sparse retrieval, could enhance the effectiveness of RAGsystems. Research shouldexplorehowtointegratedifferent retrieval methodstoachieveoptimal performancefordiversetasks.\\n6.7 Integration with Emerging Technologies: Integrating RAGmodels with brain-computer interfaces(BCIs) could lead to novel applications in human-computer interaction and assistive technologies.Research should explore how RAG systems can leverage BCI data to enhance user experience andgenerate context-aware responses.The integration of RAG with AR and VR technologies presentsopportunities for creating immersive and interactive experiences. FutureresearchshouldinvestigatehowRAG models can be used to enhance AR and VR applications by providing contextually relevantinformationandinteractions.\\n7. Conclusion\\nRetrieval-Augmented Generation (RAG) has undergone significant evolution, with extensive researchdedicated to improving retrieval effectiveness and enhancing coherent generation to minimizehallucinations. Fromitsearlyiterationstorecent advancements, RAGhasbeeninstrumental inintegratingexternal knowledge into Large Language Models (LLMs), thereby boosting accuracy and reliability. Inparticular, recent domain-specific work has showcased RAG's potential in specialized areas such aslegal, medical, and low-resource language applications, highlighting its adaptability andscope. However,despite these advances, this paper identifies clear gaps that remain unresolved. Challengessuchastheintegration of ambiguous or unstructured information, effective handling of domain-specific contexts, andthe high computational overhead of complex retrieval tasks still persist. These limitations constrain thebroader applicability of RAG systems, particularly in diverse and dynamic real-world environments. Thefuture research directions outlined in this paper—ranging from improving retrieval mechanisms toenhancing context management and ensuring scalability—will serveasacritical guideforthenext phaseof innovation in this space. By addressing these gaps, the next generation of RAG models has thepotential to drive more reliable, efficient, and domain-adaptable LLM systems, further pushing theboundariesof what ispossibleinretrieval-augmentedAI applications.\"),\n",
       " Document(metadata={'producer': 'Skia/PDF m131 Google Docs Renderer', 'creator': 'PyPDF', 'creationdate': '', 'title': 'A Comprehensive Review of Retrieval-Augmented Generation (RAG): Key Challenges and Future Directions', 'source': 'rag.pdf', 'total_pages': 18, 'page': 13, 'page_label': '14'}, page_content='References:\\nAcharya, A., Murthy, R., Kumar, V., &Sen, J. (2024). NLLB-E5: AScalable Multilingual Retrieval Model.ArXiv. /abs/2409.05401\\nAlayrac, J., Donahue, J., Luc, P., Miech, A., Barr, I., Hasson, Y., Lenc, K., Mensch, A., Millican, K.,Reynolds, M., Ring, R., Rutherford, E., Cabi, S., Han, T., Gong, Z., Samangooei, S., Monteiro, M.,Menick, J., Borgeaud, S., . . . Simonyan, K. (2022). Flamingo: AVisual Language Model for Few-ShotLearning. ArXiv. /abs/2204.14198\\nAsai, A., Wu, Z., Wang, Y., Sil, A., &Hajishirzi, H. (2023). Self-RAG: Learning to retrieve, generate, andcritiquethroughself-reflection. arXivpreprint arXiv:2310.11511.\\nBaevski, A., Zhou, H., Mohamed, A., &Auli, M. (2020). Wav2vec 2.0: AFramework for Self-SupervisedLearningof SpeechRepresentations. ArXiv. /abs/2006.11477\\nBertasius, G., Wang, H., & Torresani, L. (2021). Is Space-Time Attention All You Need for VideoUnderstanding?ArXiv. /abs/2102.05095\\nBinns, R. (2018). Fairness in machine learning: Lessons frompolitical philosophy. Proceedings of the2018ConferenceonFairness, Accountability, andTransparency(pp. 149-159).\\nBorgeaud, S., Mensch, A., Hoffmann, J., Cai, T., Rutherford, E., Millican, K., Driessche, G. V., Lespiau, J.,Damoc, B., Clark, A., Casas, D. D., Guy, A., Menick, J., Ring, R., Hennigan, T., Huang, S., Maggiore, L.,Jones, C., Cassirer, A., . . . Sifre, L. (2021). Improving language models by retrieving fromtrillions oftokens. ArXiv. /abs/2112.04426\\nBrown, T., et al. (2020). \"LanguageModelsareFew-Shot Learners.\"arXivpreprint arXiv:2005.14165.\\nChang, R., & Zhang, J. (2024). CommunityKG-RAG: Leveraging Community Structures in KnowledgeGraphsforAdvancedRetrieval-AugmentedGenerationinFact-Checking. ArXiv. /abs/2408.08535\\nChen, D., Fisch, A., Weston, J., & Bordes, A. (2017). Reading Wikipedia to answer open-domainquestions. In Proceedings of the 55th Annual Meeting of the Association for Computational Linguistics(Volume1: LongPapers)(pp. 1870-1879).\\nChen, W., Hu, H., Chen, X., Verga, P., &Cohen, W. W. (2022). MuRAG: Multimodal Retrieval-AugmentedGeneratorforOpenQuestionAnsweringoverImagesandText. ArXiv. /abs/2210.02928\\nChirkova, N., Rau, D., Déjean, H., Formal, T., Clinchant, S., &Nikoulina, V. (2024). Retrieval-augmentedgenerationinmultilingual settings. ArXiv. /abs/2407.01463\\nDai, Z., & Callan, J. (2019). Context-Aware Sentence/Passage Term Importance Estimation For FirstStageRetrieval. ArXiv. /abs/1910.10687\\nDevlin, J., Chang, M. W., Lee, K., & Toutanova, K. (2019). BERT: Pre-training of deep bidirectionaltransformers for language understanding. In Proceedings of the 2019 Conference of theNorthAmericanChapter of the Association for Computational Linguistics: Human Language Technologies (pp.4171-4186).'),\n",
       " Document(metadata={'producer': 'Skia/PDF m131 Google Docs Renderer', 'creator': 'PyPDF', 'creationdate': '', 'title': 'A Comprehensive Review of Retrieval-Augmented Generation (RAG): Key Challenges and Future Directions', 'source': 'rag.pdf', 'total_pages': 18, 'page': 14, 'page_label': '15'}, page_content='Devlin, J., Chang, M., Lee, K., & Toutanova, K. (2018). BERT: Pre-training of Deep BidirectionalTransformersforLanguageUnderstanding. ArXiv. /abs/1810.04805\\nGan, C., Yang, D., Hu, B., Zhang, H., Li, S., Liu, Z., Shen, Y., Ju, L., Zhang, Z., Gu, J., Liang, L., &Zhou,J. (2024). Similarity is Not All You Need: Endowing Retrieval Augmented Generation with Multi LayeredThoughts. ArXiv. /abs/2405.19893\\nGatt, A., &Krahmer, &E. (2018). Surveyof thestateof theart innatural languagegeneration: Coretasks,applications, andevaluation. Journal of Artificial IntelligenceResearch, 61, 65-170.\\nGupta, S., &Ranjan, R. (2024). Evaluation of LLMs Biases TowardsEliteUniversities: APersona-BasedExploration. ArXiv. /abs/2407.12801\\nGupta, S., Ranjan, R., & Singh, S. N. (2024). Comprehensive Study on Sentiment Analysis: FromRule-basedtomodernLLMbasedsystem. ArXiv. /abs/2409.09989\\nGuu, J., Lee, K., & Pasupat, P. (2020). Retrieval-augmented generation for knowledge-intensive NLPtasks. arXivpreprint. https://arxiv.org/abs/2002.08909\\nGuu, K., Lee, K., Tung, Z., Pasupat, P., & Chang, M. (2020). REALM: Retrieval-augmented languagemodel pre-training. In Proceedings of the 37th International Conference on Machine Learning (pp.3929-3938).\\nHan, S., Pool, J., Tran, J., & Dally, W. J. (2015). Learning both weights and connections for efficientneural network. InAdvancesinNeural InformationProcessingSystems(pp. 1135-1143).\\nIzacard, G., & Grave, E. (2021). Leveraging passage retrieval with generative models for open domainquestion answering. In Proceedings of the 16th Conference of the European Chapter of the AssociationforComputational Linguistics: MainVolume(pp. 874-880).\\nJi, Z., Lee, N., Frieske, R., Yu, T., Su, D., Xu, Y., Ishii, E., Bang, Y., Chen, D., Dai, W., Chan, H. S.,Madotto, A., & Fung, P. (2022). Survey of Hallucination in Natural Language Generation. ArXiv.https://doi.org/10.1145/3571730\\nKalra, R., Wu, Z., Gulley, A., Hilliard, A., Guan, X., Koshiyama, A., &Treleaven, P. (2024). HyPA-RAG: AHybridParameterAdaptiveRetrieval-AugmentedGenerationSystemforAI Legal andPolicyApplications.ArXiv. /abs/2409.09046\\nKarpukhin, V., Oguz, B., Min, S., & Yih, W. (2020). Dense passage retrieval for open-domain questionanswering. arXivpreprint. https://arxiv.org/abs/2004.04906\\nKarpukhin, V., Oguz, B., Min, S., Lewis, P., Wu, L., Edunov, S., Chen, D. & Yih, W. T. (2020). Densepassage retrieval for open-domain question answering. In Proceedings of the 2020 Conference onEmpirical MethodsinNatural LanguageProcessing(EMNLP)(pp. 6769-6781).\\nLewis, P., Perez, E., Piktus, A., Petroni, F., Karpukhin, V., Goyal, N., ... & Riedel, S. (2020).Retrieval-augmented generation for knowledge-intensive NLP tasks. In Proceedings of the 34thInternational ConferenceonNeural InformationProcessingSystem(pp. 9459-9474).'),\n",
       " Document(metadata={'producer': 'Skia/PDF m131 Google Docs Renderer', 'creator': 'PyPDF', 'creationdate': '', 'title': 'A Comprehensive Review of Retrieval-Augmented Generation (RAG): Key Challenges and Future Directions', 'source': 'rag.pdf', 'total_pages': 18, 'page': 15, 'page_label': '16'}, page_content='Li, C., Liu, Z., Xiao, S., & Shao, Y. (2023). Making Large Language Models A Better Foundation ForDenseRetrieval. ArXiv. /abs/2312.15503\\nLi, F., Zhu, L., Wang, T., Li, J., Zhang, Z., & Shen, H. T. (2023). Cross-Modal Retrieval: ASystematicReviewof MethodsandFutureDirections. ArXiv. /abs/2308.14263\\nLi, S., Shang, H., Wei, D., Guo, J., Li, Z., He, X., Zhang, M., & Yang, H. (2024). LA-RAG:EnhancingLLM-basedASRAccuracywithRetrieval-AugmentedGeneration. ArXiv. /abs/2409.08597\\nLi, S., Park, S., Lee, I., & Bastani, O. (2023). TRAQ: Trustworthy Retrieval Augmented QuestionAnsweringviaConformal Prediction. ArXiv. /abs/2307.04642\\nLi, Z., Li, C., Zhang, M., Mei, Q., & Bendersky, M. (2024). Retrieval Augmented Generation orLong-Context LLMs?AComprehensiveStudyandHybridApproach. ArXiv. /abs/2407.16833\\nLiu, Z., Wang, H., Niu, Z., Wu, H., Che, W., &Liu, T. (2020). Towards Conversational RecommendationoverMulti-TypeDialogs. ArXiv. /abs/2005.03954\\nMallen, A., Asai, A., Zhong, V., Das, R., Khashabi, D., & Hajishirzi, H. (2022). When Not to TrustLanguage Models: Investigating Effectiveness of Parametric and Non-Parametric Memories. ArXiv./abs/2212.10511\\nMombaerts, L., Ding, T., Banerjee, A., Felice, F., Taws, J., &Borogovac, T. (2024). Meta Knowledge forRetrieval AugmentedLargeLanguageModels. ArXiv. /abs/2408.09017\\nNguyen, X., Pandit, S., Purushwalkam, S., Xu, A., Chen, H., Ming, Y., Ke, Z., Savarese, S., Xong, C., &Joty, S. (2024). SFR-RAG: TowardsContextuallyFaithful LLMs. ArXiv. /abs/2409.09916\\nNiu, C., Wu, Y., Zhu, J., Xu, S., Shum, K., Zhong, R., Song, J., & Zhang, T. (2023). RAGTruth: AHallucination Corpus for Developing Trustworthy Retrieval-Augmented Language Models. ArXiv./abs/2401.00396\\nQian, H., Zhang, P., Liu, Z., Mao, K., &Dou, Z. (2024). MemoRAG: Moving towards Next-Gen RAGViaMemory-InspiredKnowledgeDiscovery. ArXiv. /abs/2409.05591\\nRadford, A., Wu, J., Child, R., Luan, D., Amodei, D., & Sutskever, I. (2019). Language models areunsupervisedmultitasklearners. OpenAI Blog, 1(8), 9.\\nRaffel, C., Shazeer, N., Roberts, A., Lee, K., Narang, S., Matena, M., Zhou, Y., Li, W., &Liu, P. J. (2019).ExploringtheLimitsof TransferLearningwithaUnifiedText-to-Text Transformer. ArXiv. /abs/1910.10683\\nRanade, P., & Joshi, A. (2023). FABULA: Intelligence Report Generation Using Retrieval-AugmentedNarrativeConstruction. ArXiv. https://doi.org/10.1145/3625007.3627505\\nRanjan, R., Gupta, S., & Singh, S. N. (2024). A Comprehensive Survey of Bias in LLMs: CurrentLandscapeandFutureDirections. ArXiv. /abs/2409.16430\\nRavuru, C., Sakhinana, S. S., &Runkana, V. (2024). Agentic Retrieval-Augmented Generation for TimeSeriesAnalysis. ArXiv. /abs/2408.14484'),\n",
       " Document(metadata={'producer': 'Skia/PDF m131 Google Docs Renderer', 'creator': 'PyPDF', 'creationdate': '', 'title': 'A Comprehensive Review of Retrieval-Augmented Generation (RAG): Key Challenges and Future Directions', 'source': 'rag.pdf', 'total_pages': 18, 'page': 16, 'page_label': '17'}, page_content=\"Robertson, S.G., & Zaragoza,H., (2009). The Probabilistic Relevance Framework: BM25 and Beyond,FoundationsandTrendsinInformationRetrieval, 3(4), pp. 333-389.\\nRoller, S., Dinan, E., Goyal, N., Ju, D., Williamson, M., Liu, Y., Xu, J., Ott, M., Shuster, K., Smith, E. M.,Boureau, Y., &Weston, J. (2020). Recipesforbuildinganopen-domainchatbot. ArXiv. /abs/2004.13637\\nSalton, G., Wong, A., & Yang, C. S. (1975). A vector space model for automatic indexing.Communicationsof theACM, 18(11), 613-620.\\nSanh, V., Debut, L., Chaumond, J., & Wolf, T. (2019). DistilBERT, a distilled version of BERT: Smaller,faster, cheaperandlighter. ArXiv. /abs/1910.01108\\nSarthi, P., Abdullah, S., Tuli, A., Khanna, S., Goldie, A., &Manning, C. D. (2024). RAPTOR: RecursiveAbstractiveProcessingforTree-OrganizedRetrieval. ArXiv. /abs/2401.18059\\nShi, W., Min, S., Yasunaga, M., Seo, M., James, R., Lewis, M., Zettlemoyer, L., & Yih, W.-T. (2023).REPLUG: Retrieval-augmentedblack-boxlanguagemodels. arXivpreprint arXiv:2301.12652.\\nShrestha, R., Zou, Y., Chen, Q., Li, Z., Xie, Y., &Deng, S. (2024). FairRAG: Fair Human GenerationviaFairRetrieval Augmentation. ArXiv. /abs/2403.19964\\nSutskever, I., Vinyals, O., & Le, Q. V. (2014). Sequence to sequence learning with neural networks. InAdvancesinNeural InformationProcessingSystems(pp. 3104-3112).\\nThakur, N., Bonifacio, L., Zhang, X., Ogundepo, O., Kamalloo, E., Li, X., Liu, Q., Chen, B.,Rezagholizadeh, M., &Lin, J. (2023). NoMIRACL: KnowingWhenYouDon't KnowforRobust MultilingualRetrieval-AugmentedGeneration. ArXiv. /abs/2312.11361\\nThakur, N., Reimers, N., Ruckl'e, A., Srivastava, A., & Gurevych, I. (2021). BEIR: A HeterogenousBenchmarkforZero-shot Evaluationof InformationRetrieval Models. ArXiv, abs/2104.08663.\\nVaswani, A., Shazeer, N., Parmar, N., Uszkoreit, J., Jones, L., Gomez, A. N., Kaiser, Ł., &Polosukhin, I.(2017). Attentionisall youneed. InAdvancesinNeural InformationProcessingSystems(pp. 5998-6008).\\nWang, X., Wang, Z., Gao, X., Zhang, F., Wu, Y., Xu, Z., Shi, T., Wang, Z., Li, S., Qian, Q., Yin, R., Lv, C.,Zheng, X., &Huang, X. (2024). Searching for Best Practices in Retrieval-Augmented Generation. ArXiv./abs/2407.01219\\nWang, Z., Araki, J., Jiang, Z., Parvez, M. R., & Neubig, G. (2023). Learning to Filter Context forRetrieval-AugmentedGeneration. ArXiv. /abs/2311.08377\\nXia, P., Zhu, K., Li, H., Zhu, H., Li, Y., Li, G., Zhang, L., &Yao, H. (2024). RULE: ReliableMultimodal RAGforFactualityinMedical VisionLanguageModels. ArXiv. /abs/2407.05131\\nXie, S., Sun, C., Huang, J., Tu, Z., & Murphy, K. (2017). Rethinking Spatiotemporal Feature Learning:Speed-AccuracyTrade-offsinVideoClassification. ArXiv. /abs/1712.04851\\nXiong, L., Xiong, C., Li, Y., Tang, K., Liu, J., Bennett, P., Ahmed, J., &Overwijk, A. (2020). ApproximateNearest NeighborNegativeContrastiveLearningforDenseText Retrieval. ArXiv. /abs/2007.00808\"),\n",
       " Document(metadata={'producer': 'Skia/PDF m131 Google Docs Renderer', 'creator': 'PyPDF', 'creationdate': '', 'title': 'A Comprehensive Review of Retrieval-Augmented Generation (RAG): Key Challenges and Future Directions', 'source': 'rag.pdf', 'total_pages': 18, 'page': 17, 'page_label': '18'}, page_content='Yasunaga, M., Aghajanyan, A., Shi, W., James, R., Leskovec, J., Liang, P., Lewis, M., Zettlemoyer, L., &Yih, W. (2022). Retrieval-AugmentedMultimodal LanguageModeling. ArXiv. /abs/2211.12561\\nZhang, T., Patil, S. G., Jain, N., Shen, S., Zaharia, M., Stoica, I., & Gonzalez, J. E. (2024). RAFT:AdaptingLanguageModel toDomainSpecificRAG. ArXiv. /abs/2403.10131\\nZhu, Y., Ren, C., Xie, S., Liu, S., Ji, H., Wang, Z., Sun, T., He, L., Li, Z., Zhu, X., & Pan, C. (2024).REALM: RAG-Driven Enhancement of Multimodal Electronic Health Records Analysis via LargeLanguageModels. ArXiv. /abs/2402.07016')]"
      ]
     },
     "execution_count": 112,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "id": "e8786e44-4990-49ff-a2ff-49b5f58322f3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# split into chunks\n",
    "\n",
    "from langchain_text_splitters import RecursiveCharacterTextSplitter\n",
    "text_splitter = RecursiveCharacterTextSplitter(chunk_size=1000, chunk_overlap=20)\n",
    "docs = text_splitter.split_documents(pages)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "id": "4330e3f9-6479-479a-8a15-cb13fcf43cc6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Document(metadata={'producer': 'Skia/PDF m131 Google Docs Renderer', 'creator': 'PyPDF', 'creationdate': '', 'title': 'A Comprehensive Review of Retrieval-Augmented Generation (RAG): Key Challenges and Future Directions', 'source': 'rag.pdf', 'total_pages': 18, 'page': 0, 'page_label': '1'}, page_content='A Comprehensive Survey of Retrieval-Augmented Generation (RAG): Evolution, CurrentLandscapeandFutureDirections\\nShailjaGupta(CarnegieMellonUniversity, USA)RajeshRanjan(CarnegieMellonUniversity, USA)SuryaNarayanSingh(BITSindri, India)\\nAbstract'),\n",
       " Document(metadata={'producer': 'Skia/PDF m131 Google Docs Renderer', 'creator': 'PyPDF', 'creationdate': '', 'title': 'A Comprehensive Review of Retrieval-Augmented Generation (RAG): Key Challenges and Future Directions', 'source': 'rag.pdf', 'total_pages': 18, 'page': 0, 'page_label': '1'}, page_content='This paper presents a comprehensive study of Retrieval-Augmented Generation (RAG), tracing itsevolution fromfoundational concepts to the current state of theart. RAGcombinesretrieval mechanismswith generative language modelstoenhancetheaccuracyof outputs, addressingkeylimitationsof LLMs.Thestudyexploresthebasicarchitectureof RAG, focusingonhowretrieval andgenerationareintegratedto handle knowledge-intensive tasks. Adetailed reviewof the significant technological advancements inRAG is provided, including key innovations in retrieval-augmented language models and applicationsacross various domains such as question-answering, summarization, and knowledge-based tasks.Recent research breakthroughs are discussed, highlighting novel methods for improving retrievalefficiency. Furthermore, the paper examines ongoing challenges such as scalability, bias, and ethicalconcerns in deployment. Future research directions are proposed, with a focus on improving therobustness of RAGmodels, expanding'),\n",
       " Document(metadata={'producer': 'Skia/PDF m131 Google Docs Renderer', 'creator': 'PyPDF', 'creationdate': '', 'title': 'A Comprehensive Review of Retrieval-Augmented Generation (RAG): Key Challenges and Future Directions', 'source': 'rag.pdf', 'total_pages': 18, 'page': 0, 'page_label': '1'}, page_content='expanding the scope of application of RAGmodels, andaddressingsocietalimplications. This survey aims to serve as a foundational resource for researchers and practitioners inunderstandingthepotential of RAGanditstrajectoryinthefieldof natural languageprocessing.'),\n",
       " Document(metadata={'producer': 'Skia/PDF m131 Google Docs Renderer', 'creator': 'PyPDF', 'creationdate': '', 'title': 'A Comprehensive Review of Retrieval-Augmented Generation (RAG): Key Challenges and Future Directions', 'source': 'rag.pdf', 'total_pages': 18, 'page': 0, 'page_label': '1'}, page_content='Figure1: TrendsinRAGcapturedfromrecent researchpapers\\nKeywords: Retrieval-Augmented Generation (RAG), InformationRetrieval, Natural LanguageProcessing(NLP), Artificial Intelligence(AI), MachineLearning(ML), LargeLanguageModel (LLM).'),\n",
       " Document(metadata={'producer': 'Skia/PDF m131 Google Docs Renderer', 'creator': 'PyPDF', 'creationdate': '', 'title': 'A Comprehensive Review of Retrieval-Augmented Generation (RAG): Key Challenges and Future Directions', 'source': 'rag.pdf', 'total_pages': 18, 'page': 1, 'page_label': '2'}, page_content=\"Introduction\\n1.1IntroductionofNatural LanguageGeneration(NLG)\\nNatural Language Processing (NLP) has become a pivotal domain within artificial intelligence (AI), withapplications ranging from simple text classification to more complex tasks such as summarization,machinetranslation, andquestionanswering. Aparticularlysignificant branchof NLPisNatural LanguageGeneration (NLG), which focuses on the production of human-like language from structured orunstructured data. NLG's goal is to enable machines to generate coherent, relevant, and context-awaretext, improvinginteractionsbetweenhumansandmachines(Gatt et. al. 2018). AsAI evolves, thedemandfor more contextually awareandfactuallygroundedgeneratedcontent hasincreased, bringingabout newchallengesandinnovationsinNLG.\"),\n",
       " Document(metadata={'producer': 'Skia/PDF m131 Google Docs Renderer', 'creator': 'PyPDF', 'creationdate': '', 'title': 'A Comprehensive Review of Retrieval-Augmented Generation (RAG): Key Challenges and Future Directions', 'source': 'rag.pdf', 'total_pages': 18, 'page': 1, 'page_label': '2'}, page_content='Traditional NLG models, especially sequence-to-sequence architectures (Sutskever et al. 2014), haveexhibited significant advancements ingeneratingfluent andcoherent text. However, thesemodelstendtorely heavily on training data, often struggling when tasked with generating factually accurate orcontextually rich content for queries that require knowledge beyond theirtrainingset. Asaresult, modelslike GPT (Radford et al. 2019) or BERT-based (Devlin et al. 2019) text generators are prone tohallucinations, where they produceplausiblebut incorrect ornon-existent information(Ji et al. 2022). Thislimitation has prompted the exploration of hybrid models that combine retrieval mechanisms withgenerative capabilities to ensure both fluency and factual correctness in outputs. There has been asignificant rise in several research papers in this field and several new methods across the RAGcomponents have been proposed. Apart fromnew algorithms and methods, RAGhas also seen steepadoption across'),\n",
       " Document(metadata={'producer': 'Skia/PDF m131 Google Docs Renderer', 'creator': 'PyPDF', 'creationdate': '', 'title': 'A Comprehensive Review of Retrieval-Augmented Generation (RAG): Key Challenges and Future Directions', 'source': 'rag.pdf', 'total_pages': 18, 'page': 1, 'page_label': '2'}, page_content='across various applications. However, there is a gapinasufficient surveyof thisspacetrackingtheevolutionandrecent changesinthisspace. Thecurrent surveyintendstofill thisgap.'),\n",
       " Document(metadata={'producer': 'Skia/PDF m131 Google Docs Renderer', 'creator': 'PyPDF', 'creationdate': '', 'title': 'A Comprehensive Review of Retrieval-Augmented Generation (RAG): Key Challenges and Future Directions', 'source': 'rag.pdf', 'total_pages': 18, 'page': 1, 'page_label': '2'}, page_content='1.2OverviewofRetrieval-AugmentedGeneration(RAG)\\nRetrieval-Augmented Generation (RAG) is an emerging hybrid architecture designed to address thelimitations of pure generative models. RAG integrates two key components: (i) a retrieval mechanism,which retrieves relevant documents or information from an external knowledge source, and (ii) ageneration module, which processesthisinformationtogeneratehuman-liketext (Lewiset al. 2020). Thiscombination allows RAG models to not only generate fluent text but also ground their outputs inreal-world, up-to-datedata.'),\n",
       " Document(metadata={'producer': 'Skia/PDF m131 Google Docs Renderer', 'creator': 'PyPDF', 'creationdate': '', 'title': 'A Comprehensive Review of Retrieval-Augmented Generation (RAG): Key Challenges and Future Directions', 'source': 'rag.pdf', 'total_pages': 18, 'page': 1, 'page_label': '2'}, page_content='The retrieval module in RAG typically leverages dense vector representations to identify relevantdocuments from large datasets, such as Wikipedia or proprietary databases. Once retrieved, thesedocuments are passed to the generative module, often built using transformer-based architectures, togenerate responses grounded in the retrieved knowledge. This methodology helps mitigate thehallucination problemand ensures that the generated text is more factual and contextually appropriate(Thakur et al. 2021). Over the period, RAGmodels have seen applicationsinvariousdomains, includingopen-domain question answering (Karpukhin et al., 2020), conversational agents (Liu et al. 2021), andpersonalizedrecommendations.'),\n",
       " Document(metadata={'producer': 'Skia/PDF m131 Google Docs Renderer', 'creator': 'PyPDF', 'creationdate': '', 'title': 'A Comprehensive Review of Retrieval-Augmented Generation (RAG): Key Challenges and Future Directions', 'source': 'rag.pdf', 'total_pages': 18, 'page': 2, 'page_label': '3'}, page_content='Figure2: Abasicflowof theRAGsystemalongwithitscomponent\\n1.3EvolutionofHybridModelsinNLP\\nBefore the introduction of RAG, NLPmodelsprimarilyreliedoneitherretrieval orgenerationapproaches,each with its own set of advantages and limitations. Retrieval-based systems, such as traditionalinformation retrieval engines (Salton et al., 1975), efficiently provided relevant documents or snippets inresponse to a query but could not synthesize new information or present the results in a coherentnarrative. On the other hand, purely generative models, which became popular with the rise oftransformer architectures (Vaswani et al. 2017), offered fluency and creativity but often lacked factualaccuracy.'),\n",
       " Document(metadata={'producer': 'Skia/PDF m131 Google Docs Renderer', 'creator': 'PyPDF', 'creationdate': '', 'title': 'A Comprehensive Review of Retrieval-Augmented Generation (RAG): Key Challenges and Future Directions', 'source': 'rag.pdf', 'total_pages': 18, 'page': 2, 'page_label': '3'}, page_content='The development of hybrid systems combining retrieval and generation began to gain momentumasresearchers recognizedthecomplementarystrengthsof bothapproaches. Earlyeffortsinhybridmodelingcan be traced back to works like DrQA(Chen et al. 2017), which employed retrieval techniques to fetchrelevant documents for question-answering tasks. However, the generative component in such systemswas minimal, often limited to selecting text directlyfromtheretrieveddocuments. Similarly, inmodelslikeInformationRetrieval (Dai et al. 2019), retrieval wastreatedasdistinct, independent components.'),\n",
       " Document(metadata={'producer': 'Skia/PDF m131 Google Docs Renderer', 'creator': 'PyPDF', 'creationdate': '', 'title': 'A Comprehensive Review of Retrieval-Augmented Generation (RAG): Key Challenges and Future Directions', 'source': 'rag.pdf', 'total_pages': 18, 'page': 2, 'page_label': '3'}, page_content='The real innovation came with the realization that retrieval and generation could be tightly integrated.Models like REALM (Guu et al., 2020) represented a key milestone, as they trained the retrieval andgenerative components jointly, enabling better alignment between the retrieved information and thegenerated output. RAG (Lewis et al. 2020) further extended this paradigm by using dense passageretrieval (Karpukhin et al., 2020) to fetch relevant documents and transformers like BART(Lewis et al.,2020) for a generation. This architecture provided a more seamless integration of retrieval andgeneration, allowingthemodel toansweropen-endedquestionswithbothfluencyandfactual grounding.\\n1.4ImportanceofFactuallyGroundedLanguageGeneration'),\n",
       " Document(metadata={'producer': 'Skia/PDF m131 Google Docs Renderer', 'creator': 'PyPDF', 'creationdate': '', 'title': 'A Comprehensive Review of Retrieval-Augmented Generation (RAG): Key Challenges and Future Directions', 'source': 'rag.pdf', 'total_pages': 18, 'page': 2, 'page_label': '3'}, page_content='One of the main motivations for developing RAG is the increasing demand for factually accurate,contextually relevant, and up-to-date generated content. Inmanyapplications, suchascustomerservice,medical diagnostics, or legal advisory systems, the need for reliable and grounded responses isparamount. Generative models that produce hallucinated or inaccurate information can lead to seriousconsequences, suchasspreadingmisinformationorprovidingincorrect advice(Ji et al. 2022).'),\n",
       " Document(metadata={'producer': 'Skia/PDF m131 Google Docs Renderer', 'creator': 'PyPDF', 'creationdate': '', 'title': 'A Comprehensive Review of Retrieval-Augmented Generation (RAG): Key Challenges and Future Directions', 'source': 'rag.pdf', 'total_pages': 18, 'page': 3, 'page_label': '4'}, page_content='RAG models directly address these concerns by grounding their generative process in external,up-to-date knowledge sources. This groundingimprovesthefactual accuracyof theoutput andenhancesthe relevance of responses by incorporating real-world data that is directly tiedtothequery. Additionally,RAGmodels are less likely to propagate biases present in static training data, astheycanretrievemorediverseandbalancedinformationfromexternal sources\\n1.5ApplicationsofRAGModels'),\n",
       " Document(metadata={'producer': 'Skia/PDF m131 Google Docs Renderer', 'creator': 'PyPDF', 'creationdate': '', 'title': 'A Comprehensive Review of Retrieval-Augmented Generation (RAG): Key Challenges and Future Directions', 'source': 'rag.pdf', 'total_pages': 18, 'page': 3, 'page_label': '4'}, page_content='RAG models have been applied across a wide array of domains where factual accuracy and contextualunderstanding are critical. One of themost prominent applicationsisinopen-domainquestionanswering,where the model must generate answers based on a wide range of topics. RAGhas proven effective inimproving answer accuracy byretrievingrelevant informationandthengeneratingresponsesgroundedinthat data (Izacard et. al. 2021). Models like Dense PassageRetrieval (DPR)(Karpukhinet al., 2020)andFusion-in-Decoder(Izacardet. al. 2021)havebeenusedtogreat effect inthiscontext, showingsignificantimprovementsovertraditional generativeorretrieval-onlymodels.'),\n",
       " Document(metadata={'producer': 'Skia/PDF m131 Google Docs Renderer', 'creator': 'PyPDF', 'creationdate': '', 'title': 'A Comprehensive Review of Retrieval-Augmented Generation (RAG): Key Challenges and Future Directions', 'source': 'rag.pdf', 'total_pages': 18, 'page': 3, 'page_label': '4'}, page_content=\"In conversational AI, RAGmodels have enhanced the capabilities of dialogue systems by ensuring thatresponses are both coherent and grounded in factual information (Roller et al., 2020). For example,chatbots used in customer service can benefit fromRAG's ability to retrievespecificdetailsfromproductdatabasesordocumentation, leadingtomoreaccurateanduseful responsesforend-users.\\nOther applications include medical diagnosis systems, where RAGcan retrieve and integrate the latestresearch findings or patient-specific data togenerateaccuratediagnosticsuggestions, andlegal advisorysystems, where the model can retrieve relevant case law or statutes to provide legally sound advice.Furthermore, RAGhasfoundapplicationsinpersonalizedrecommendationsystems, whereit canretrieveuserpreferencesorpast interactionsandgeneratepersonalizedsuggestions.\\n1.6ChallengesandLimitationsofRAG\"),\n",
       " Document(metadata={'producer': 'Skia/PDF m131 Google Docs Renderer', 'creator': 'PyPDF', 'creationdate': '', 'title': 'A Comprehensive Review of Retrieval-Augmented Generation (RAG): Key Challenges and Future Directions', 'source': 'rag.pdf', 'total_pages': 18, 'page': 3, 'page_label': '4'}, page_content='Despite the promise of RAGmodels, several challenges need attention. The retrieval mechanism, whilepowerful, can still struggle with retrieving the most relevant documents, particularly when dealing withambiguous queries or niche knowledge domains. The reliance on dense vectorrepresentations, suchasthose used in DPR, can sometimes lead to irrelevant or off-topic documents being retrieved. Efforts torefine retrieval techniques, including the incorporation of more sophisticated query expansion andcontextual disambiguation, are needed to improve performance in these areas. The integration betweenretrieval and generation, while seamless in theory, can sometimes fail in practice. For instance, thegenerative module may not always effectively incorporate the retrieved information into its responses,leading to inconsistencies or incoherence between the retrieved facts and the generated text. Researchinto better alignment mechanisms, such as improved attention models or hierarchical fusion'),\n",
       " Document(metadata={'producer': 'Skia/PDF m131 Google Docs Renderer', 'creator': 'PyPDF', 'creationdate': '', 'title': 'A Comprehensive Review of Retrieval-Augmented Generation (RAG): Key Challenges and Future Directions', 'source': 'rag.pdf', 'total_pages': 18, 'page': 3, 'page_label': '4'}, page_content='hierarchical fusion techniques,may help alleviate these issues (Izacard et. al. 2021). Additionally, the computational overhead of RAGmodels is a concern, as they require both a retrieval and a generation step for each query. This dualprocess can be resource-intensive, particularly for large-scale applications (Borgeaud et al. 2021).Techniques such as model pruning (Han et al. 2015) or knowledge distillation (Sanh et al., 2019) mayoffer ways to reduce the computational burden without sacrificing performance. Finally, there are ethicalconcerns associated with the deployment of RAGmodels, particularly in termsof biasandtransparency.Biases in AI and LLM have been a well-researched and evolving field with researchers identifyingdifferent types of biases not limited to Gender, socio-economic class, or even educational background(Gupta et. al. 2024; Ranjan et. al., 2024). While RAG has the potential to reduce biases by retrievingmore balanced information, there is still the risk of'),\n",
       " Document(metadata={'producer': 'Skia/PDF m131 Google Docs Renderer', 'creator': 'PyPDF', 'creationdate': '', 'title': 'A Comprehensive Review of Retrieval-Augmented Generation (RAG): Key Challenges and Future Directions', 'source': 'rag.pdf', 'total_pages': 18, 'page': 3, 'page_label': '4'}, page_content='still the risk of amplifying biases present in the retrieved sources'),\n",
       " Document(metadata={'producer': 'Skia/PDF m131 Google Docs Renderer', 'creator': 'PyPDF', 'creationdate': '', 'title': 'A Comprehensive Review of Retrieval-Augmented Generation (RAG): Key Challenges and Future Directions', 'source': 'rag.pdf', 'total_pages': 18, 'page': 4, 'page_label': '5'}, page_content='(Binns, 2018). Furthermore, ensuring transparency in how retrieval results are selected and used ingenerationiscrucial formaintainingtrust inthesesystems.\\n1.7ScopeoftheSurvey\\nThis paper aims to provide a comprehensive survey of RAG models, covering their evolution, keyarchitectural components, recent research in this area, current challenges and limitations of RAG, andfutureresearchdirection.\\n2:CoreComponentsandArchitectural OverviewofRAGSystems\\n2.1OverviewofRAGModels'),\n",
       " Document(metadata={'producer': 'Skia/PDF m131 Google Docs Renderer', 'creator': 'PyPDF', 'creationdate': '', 'title': 'A Comprehensive Review of Retrieval-Augmented Generation (RAG): Key Challenges and Future Directions', 'source': 'rag.pdf', 'total_pages': 18, 'page': 4, 'page_label': '5'}, page_content=\"Retrieval-augmented generation (RAG) is an advanced hybrid model architecture that augments naturallanguage generation (NLG) with external retrieval mechanisms to enhance themodel'sknowledgebase.Traditional large language models (LLMs) such as GPT-3 and BERT, which are pre-trained on vastcorpora, rely entirely on their internal representations of knowledge, making themsusceptible to issueslike hallucinations—where the models generate plausible but incorrect information. Thesemodelscannotefficiently update their knowledge bases without retraining, making them less practical for dynamic,knowledge-intensive tasks like open-domain question answering and fact verification (Brown, T., et al.2020). Toovercometheselimitations, thepaper(Lewiset al. 2020)proposedtheRAGarchitecture, whichretrievesreal-time, relevant external documentstogroundthegeneratedtext infactual information.\\nTheRAGmodel incorporatestwokeycomponents:\"),\n",
       " Document(metadata={'producer': 'Skia/PDF m131 Google Docs Renderer', 'creator': 'PyPDF', 'creationdate': '', 'title': 'A Comprehensive Review of Retrieval-Augmented Generation (RAG): Key Challenges and Future Directions', 'source': 'rag.pdf', 'total_pages': 18, 'page': 4, 'page_label': '5'}, page_content='1. Retriever: This retrieves the most relevant documents froma corpus using techniques such asdensepassageretrieval (DPR)(Karpukhinet. al. 2020)ortraditional BM25algorithms.2. Generator: It synthesizes the retrieved documents into coherent, contextually relevantresponses.'),\n",
       " Document(metadata={'producer': 'Skia/PDF m131 Google Docs Renderer', 'creator': 'PyPDF', 'creationdate': '', 'title': 'A Comprehensive Review of Retrieval-Augmented Generation (RAG): Key Challenges and Future Directions', 'source': 'rag.pdf', 'total_pages': 18, 'page': 4, 'page_label': '5'}, page_content='RAG’s strength lies in its ability to leverage external knowledge dynamically, allowing it to outperformgenerative models like GPT-3andknowledge-groundedsystemslikeBERT, whichrelyonstaticdatasets.In open-domain question answering, RAG has been demonstrated to be highly effective, consistentlyretrievingrelevant informationandimprovingthefactual accuracyof thegeneratedresponses(Guu, K., etal. 2020). In addition to knowledge retrieval, RAGmodels excel at updating knowledgebases. Sincethemodel fetches external documents for each query, it requires no retraining to incorporate the latestinformation. This flexibility makes RAG models particularly suitable for domains where information isconstantly evolving, such as medical research, financial news, and legal proceedings. Furthermore,studies have shown that RAGmodels achieve superior results in a varietyof knowledge-intensivetasks,includingdocument summarizationand, knowledge-groundeddialogues\\n2.2RetrieverMechanismsinRAGSystems'),\n",
       " Document(metadata={'producer': 'Skia/PDF m131 Google Docs Renderer', 'creator': 'PyPDF', 'creationdate': '', 'title': 'A Comprehensive Review of Retrieval-Augmented Generation (RAG): Key Challenges and Future Directions', 'source': 'rag.pdf', 'total_pages': 18, 'page': 4, 'page_label': '5'}, page_content=\"The retriever in RAG systems is essential for fetching relevant documents from an external corpus.Effective retrieval ensures that the model's output is grounded in accurate information. Several retrievalmechanisms are commonly used, ranging from traditional methods like BM25 to more sophisticatedtechniqueslikeDensePassageRetrieval (DPR).\"),\n",
       " Document(metadata={'producer': 'Skia/PDF m131 Google Docs Renderer', 'creator': 'PyPDF', 'creationdate': '', 'title': 'A Comprehensive Review of Retrieval-Augmented Generation (RAG): Key Challenges and Future Directions', 'source': 'rag.pdf', 'total_pages': 18, 'page': 5, 'page_label': '6'}, page_content='2.2.1BM25'),\n",
       " Document(metadata={'producer': 'Skia/PDF m131 Google Docs Renderer', 'creator': 'PyPDF', 'creationdate': '', 'title': 'A Comprehensive Review of Retrieval-Augmented Generation (RAG): Key Challenges and Future Directions', 'source': 'rag.pdf', 'total_pages': 18, 'page': 5, 'page_label': '6'}, page_content=\"BM25 is a well-established informationretrieval algorithmthat usesthetermfrequency-inversedocumentfrequency (TF-IDF) to rank documents according to relevance. Despite being a classical method, BM25remains a strong baseline for many modern retrieval systems, including those used in RAG models.BM25 calculates therelevancescoreof adocument basedonhowfrequentlyaquerytermappearsinthedocument while adjusting for the document's length and the frequency of the termacross the corpus(Robertson et. al. 2009). WhileBM25iseffectiveforkeywordmatching, it haslimitationsinunderstandingsemantic meaning. For example, BM25 cannot capture the relationships between words and tends toperform poorly on more complex, natural language queries that require an understanding of context.Despite this limitation, BM25 is still widely used because of itssimplicityandefficiency. BM25iseffectivefor tasks involvingsimpler, keyword-basedqueries, althoughmoremodernretrieval modelslikeDPRtendtooutperformit\"),\n",
       " Document(metadata={'producer': 'Skia/PDF m131 Google Docs Renderer', 'creator': 'PyPDF', 'creationdate': '', 'title': 'A Comprehensive Review of Retrieval-Augmented Generation (RAG): Key Challenges and Future Directions', 'source': 'rag.pdf', 'total_pages': 18, 'page': 5, 'page_label': '6'}, page_content='insemanticallycomplextasks.'),\n",
       " Document(metadata={'producer': 'Skia/PDF m131 Google Docs Renderer', 'creator': 'PyPDF', 'creationdate': '', 'title': 'A Comprehensive Review of Retrieval-Augmented Generation (RAG): Key Challenges and Future Directions', 'source': 'rag.pdf', 'total_pages': 18, 'page': 5, 'page_label': '6'}, page_content='2.2.2DensePassageRetrieval (DPR)'),\n",
       " Document(metadata={'producer': 'Skia/PDF m131 Google Docs Renderer', 'creator': 'PyPDF', 'creationdate': '', 'title': 'A Comprehensive Review of Retrieval-Augmented Generation (RAG): Key Challenges and Future Directions', 'source': 'rag.pdf', 'total_pages': 18, 'page': 5, 'page_label': '6'}, page_content='Dense Passage Retrieval (DPR), introduced by Karpukhin et al. (2020), represents a more modernapproach to information retrieval. It uses a dense vector space in which both the query and thedocuments are encoded into high-dimensional vectors. DPR employs a bi-encoder architecture, wherethe query and documents are encoded separately, allowing for efficient nearest-neighbor search (Xionget. al. 2020). Unlike BM25, DPR excels at capturing semantic similarity between the query anddocuments, making it highly effective for open-domain question-answering tasks. The strength of DPRlies in its ability to retrieve relevant information based on semantic meaning rather than keywordmatching. By training the retriever on a large corpus of question-answer pairs, DPRcan finddocumentsthat are contextually related to the query, even when the query and the document do not share exactterms. Recent research has further improved DPRbyintegratingit'),\n",
       " Document(metadata={'producer': 'Skia/PDF m131 Google Docs Renderer', 'creator': 'PyPDF', 'creationdate': '', 'title': 'A Comprehensive Review of Retrieval-Augmented Generation (RAG): Key Challenges and Future Directions', 'source': 'rag.pdf', 'total_pages': 18, 'page': 5, 'page_label': '6'}, page_content='DPRbyintegratingit withpre-trainedlanguagemodelsandanexampleisLLMadaptedforthedenseRetrievAl approach(Li et. al. 2023)'),\n",
       " Document(metadata={'producer': 'Skia/PDF m131 Google Docs Renderer', 'creator': 'PyPDF', 'creationdate': '', 'title': 'A Comprehensive Review of Retrieval-Augmented Generation (RAG): Key Challenges and Future Directions', 'source': 'rag.pdf', 'total_pages': 18, 'page': 5, 'page_label': '6'}, page_content='2.2.3REALM(Retrieval-AugmentedLanguageModel)'),\n",
       " Document(metadata={'producer': 'Skia/PDF m131 Google Docs Renderer', 'creator': 'PyPDF', 'creationdate': '', 'title': 'A Comprehensive Review of Retrieval-Augmented Generation (RAG): Key Challenges and Future Directions', 'source': 'rag.pdf', 'total_pages': 18, 'page': 5, 'page_label': '6'}, page_content=\"Another significant advancement in retrieval mechanisms for RAGmodels is REALM(Guu et al. (2020).REALMintegrates retrieval into the language model's pre-training process, ensuring that the retriever isoptimized alongside the generator for downstreamtasks. ThekeyinnovationinREALMisthat it learnstoretrieve documents that improve the model’s performance on specific tasks, suchasquestionansweringor document summarization. During training, REALM updates both the retriever and the generator,ensuring that the retrieval process is optimized for the generation task. REALM’s retriever is trained toidentify documents that are not only relevant to the query but also helpful for generating accurate andcoherent responses. As a result, REALM significantly improves the quality of generated responses,particularly in tasks that require external knowledge. Recent studies have demonstrated that REALMoutperforms both BM25 and DPR in certain knowledge-intensive tasks, particularly when retrieval\"),\n",
       " Document(metadata={'producer': 'Skia/PDF m131 Google Docs Renderer', 'creator': 'PyPDF', 'creationdate': '', 'title': 'A Comprehensive Review of Retrieval-Augmented Generation (RAG): Key Challenges and Future Directions', 'source': 'rag.pdf', 'total_pages': 18, 'page': 5, 'page_label': '6'}, page_content='when retrieval istightlycoupledwithgeneration.'),\n",
       " Document(metadata={'producer': 'Skia/PDF m131 Google Docs Renderer', 'creator': 'PyPDF', 'creationdate': '', 'title': 'A Comprehensive Review of Retrieval-Augmented Generation (RAG): Key Challenges and Future Directions', 'source': 'rag.pdf', 'total_pages': 18, 'page': 5, 'page_label': '6'}, page_content='The core of RAG lies in the quality of retrieved passages, but many current methods rely onsimilarity-based retrieval (Mallen et al. 2022). Self-RAG (Asai et al. 2023b), and REPLUG (Shi et al.,2023) have advanced by leveraging LLMs to enhance retrieval capabilities, achieving more adaptiveretrieval. After initial retrieval, cross-encoder models are used to re-rank the retrieved results by jointlyencoding the query and each retrieved document to compute relevance scores. These models providemore context-aware retrieval at the cost of higher computational overhead. Pointwise and PairwiseRanking, often based on Learning-to-Rank (LTR) algorithms, are used to assign relevance scores to'),\n",
       " Document(metadata={'producer': 'Skia/PDF m131 Google Docs Renderer', 'creator': 'PyPDF', 'creationdate': '', 'title': 'A Comprehensive Review of Retrieval-Augmented Generation (RAG): Key Challenges and Future Directions', 'source': 'rag.pdf', 'total_pages': 18, 'page': 6, 'page_label': '7'}, page_content='retrieved documents, either independently (pointwise) or by comparing document pairs (pairwise). RAGsystems utilizeself-attentionwithintheLLMtomanagecontext andrelevanceacrossdifferent partsof theinput and retrieved text. Cross-attentionmechanismsareusedwhenintegratingretrievedinformationintothe generative model, ensuring that the most relevant pieces of information are emphasized duringgeneration.\\n2.3GeneratorMechanismsinRAGSystems\\nIn Retrieval-Augmented Generation (RAG) systems, the generator mechanism plays a crucial role inproducing the final output by integrating retrieved information with the input query. After the retrievalcomponent pulls relevant knowledge fromexternal sources, the generator synthesizes this informationinto coherent, contextually appropriate responses. The Large Language Model (LLM) serves as thebackbone of the generator, which ensures the generated text is fluent, accurate, and aligned with theoriginal query.\\n2.3.1T5(Text-to-TextTransferTransformer)'),\n",
       " Document(metadata={'producer': 'Skia/PDF m131 Google Docs Renderer', 'creator': 'PyPDF', 'creationdate': '', 'title': 'A Comprehensive Review of Retrieval-Augmented Generation (RAG): Key Challenges and Future Directions', 'source': 'rag.pdf', 'total_pages': 18, 'page': 6, 'page_label': '7'}, page_content=\"T5 (Text-to-Text Transfer Transformer) (Raffel et al. 2020) is one of the most commonlyusedmodelsforgeneration tasks in RAGsystems. T5isversatileinitsapproach, framingeveryNLPtaskasatext-to-texttask. This uniform framework allows T5 to be fine-tuned for a wide range of tasks, includingquestion-answering, summarization, and dialogue generation. By integrating retrieval with generation,T5-based RAG models have been shown to outperformtraditional generative models like GPT-3 andBART on several benchmarks, including the Natural Questions dataset and the TriviaQA dataset.Moreover, T5's ability to handle complex multi-task learning makes it a popular choice for RAGsystemsthat needtotackleadiverserangeof knowledge-intensivetasks.\"),\n",
       " Document(metadata={'producer': 'Skia/PDF m131 Google Docs Renderer', 'creator': 'PyPDF', 'creationdate': '', 'title': 'A Comprehensive Review of Retrieval-Augmented Generation (RAG): Key Challenges and Future Directions', 'source': 'rag.pdf', 'total_pages': 18, 'page': 6, 'page_label': '7'}, page_content='2.3.2BARTBART(Bidirectional andAuto-RegressiveTransformer), introducedbyLewiset al. (2020), isanotherprominent generativemodel usedinRAGsystems. BARTisparticularlywell-suitedfortasksinvolvingtextgenerationfromnoisyinputs, suchassummarizationandopen-domainquestionanswering. Asadenoisingautoencoder, BARTcanreconstruct corruptedtext sequences, makingit robust fortasksthatrequirethegenerationof coherent, factual outputsfromincompleteornoisydata. WhenpairedwitharetrieverinaRAGsystem, BARThasbeenshowntoimprovethefactual accuracyof generatedtext bygroundingit inexternal knowledge. Studieshavedemonstratedthat BART-basedRAGmodelsachievestate-of-the-art resultsinvariousknowledge-intensivetasks, includingdialoguegenerationandnewssummarization.\\n3. Retrieval-AugmentedGenerationModelsAcrossDifferentModalities'),\n",
       " Document(metadata={'producer': 'Skia/PDF m131 Google Docs Renderer', 'creator': 'PyPDF', 'creationdate': '', 'title': 'A Comprehensive Review of Retrieval-Augmented Generation (RAG): Key Challenges and Future Directions', 'source': 'rag.pdf', 'total_pages': 18, 'page': 6, 'page_label': '7'}, page_content='3.1 Text-Based RAG Models: Text-based RAG models represent the most mature and widelyresearched category. These models leverage textual data for both retrieval and generation tasks,enabling applications such as question-answering, summarization, and conversational agents.Transformer architectures, such as BERT (Devlin et al., 2019) and T5 (Raffel et al., 2020), arefoundational in text-based RAG models. These models utilize self-attention mechanisms to capturecontextual relationships within text, which enhances both retrieval accuracy and generation fluency.Dense retrieval models, such as those using dense embeddings fromBERT, offer superior performancecompared to traditional sparse methods like TF-IDF. Dense retrievers (Karpukhin et al. 2020), leveragedense representations to retrieve relevant documents more effectively. Recent advancements focus onintegrating retrieval and generation into a single training pipeline. REALM (Guu et al., 2020) is an'),\n",
       " Document(metadata={'producer': 'Skia/PDF m131 Google Docs Renderer', 'creator': 'PyPDF', 'creationdate': '', 'title': 'A Comprehensive Review of Retrieval-Augmented Generation (RAG): Key Challenges and Future Directions', 'source': 'rag.pdf', 'total_pages': 18, 'page': 7, 'page_label': '8'}, page_content='example of such anend-to-endmodel that jointlyoptimizesretrieval andgenerationprocesses, improvingoverall taskperformance.\\n3.2 Audio-BasedRAGModels: Audio-based RAGmodels extend the principles of retrieval-augmentedgeneration to the audio modality, enablingapplicationssuchasspeechrecognition, audiosummarization,and conversational agents in voice interfaces. Audiodataisoftenrepresentedusingembeddingsderivedfrompre-trained models like Wav2Vec 2.0 (Baevski et al., 2020). These embeddings serve as input toretrieval andgenerationcomponents, enablingthemodel tohandleaudiodataeffectively.\\n3.3 Video-Based RAG Models: Video-based RAG models incorporate both visual and textualinformation to enhance performance in tasks such as video understanding, captioning, and retrieval.Video data is represented using embeddings from models like I3D (Xie et. al. 2017) or TimeSformer(Bertasius et al. 2021). These embeddings capture temporal and spatial features essential for effectiveretrieval andgeneration.'),\n",
       " Document(metadata={'producer': 'Skia/PDF m131 Google Docs Renderer', 'creator': 'PyPDF', 'creationdate': '', 'title': 'A Comprehensive Review of Retrieval-Augmented Generation (RAG): Key Challenges and Future Directions', 'source': 'rag.pdf', 'total_pages': 18, 'page': 7, 'page_label': '8'}, page_content='3.4 Multimodal RAG Models: Multimodal RAG models integrate data frommultiple modalities—text,audio, video, and images—to provide a more holistic approach to retrieval andgenerationtasks. Modelslike Flamingo (Alayrac et al., 2022) integrate multiple modalities into a unified framework, enablingsimultaneous processing of text, images, and videos. Techniques for cross-modal retrieval involveretrievingrelevant informationacrossdifferent modalities(Li. et. al. 2023).'),\n",
       " Document(metadata={'producer': 'Skia/PDF m131 Google Docs Renderer', 'creator': 'PyPDF', 'creationdate': '', 'title': 'A Comprehensive Review of Retrieval-Augmented Generation (RAG): Key Challenges and Future Directions', 'source': 'rag.pdf', 'total_pages': 18, 'page': 7, 'page_label': '8'}, page_content='Multimodal capabilities enhance the versatility and efficiency of RAG across various applications.”Retrieval as generation” (Wang et. al. 2024) extends the Retrieval-Augmented Generation (RAG)framework tomultimodal applicationsbyincorporatingtext-to-imageandimage-to-text retrieval. Utilizingalarge dataset of pairedimagesandtext descriptions, thesystemacceleratesimagegenerationwhenuserqueries align with stored text descriptions (\"retrieval as generation\"). The image-to-text functionalityallowsuserstoengageindiscussionsbasedoninput images.\\nFigure3: Timelineof theevolutionof theRAGsystemanditscomponents'),\n",
       " Document(metadata={'producer': 'Skia/PDF m131 Google Docs Renderer', 'creator': 'PyPDF', 'creationdate': '', 'title': 'A Comprehensive Review of Retrieval-Augmented Generation (RAG): Key Challenges and Future Directions', 'source': 'rag.pdf', 'total_pages': 18, 'page': 8, 'page_label': '9'}, page_content='4. RecentAdvancementinthefield:'),\n",
       " Document(metadata={'producer': 'Skia/PDF m131 Google Docs Renderer', 'creator': 'PyPDF', 'creationdate': '', 'title': 'A Comprehensive Review of Retrieval-Augmented Generation (RAG): Key Challenges and Future Directions', 'source': 'rag.pdf', 'total_pages': 18, 'page': 8, 'page_label': '9'}, page_content='There has been significant advancement in this field and this section intendstocapturekeyfindingsof afewimportant recent papers. Anovel agenticRetrieval-AugmentedGeneration(RAG)framework(Ravuruet. al. 2024) employs a hierarchical, multi-agent architecturewherespecializedsub-agents, usingsmallerpre-trained language models (SLMs), are fine-tuned for specific time series tasks. The master agentdelegates tasks to these sub-agents, who retrieve relevant prompts fromasharedknowledgerepository.In this modular, multi-agent approach, the authors achieve state-of-the-art performance demonstratingimproved flexibility and effectiveness over task-specificmethodsintimeseriesanalysis. RULE(Xiaet. al.2024), a multimodal Retrieval-Augmented Generation (RAG) framework designed to improve thefactuality of medical Vision-Language Models (Med-LVLM), addresses challenges in medical RAG byintroducing a calibrated selection strategy to control factuality risk, and, by developing a preferenceoptimization'),\n",
       " Document(metadata={'producer': 'Skia/PDF m131 Google Docs Renderer', 'creator': 'PyPDF', 'creationdate': '', 'title': 'A Comprehensive Review of Retrieval-Augmented Generation (RAG): Key Challenges and Future Directions', 'source': 'rag.pdf', 'total_pages': 18, 'page': 8, 'page_label': '9'}, page_content='strategy to balance the model’s intrinsic knowledge with retrieved contexts, proving itseffectiveness in enhancing factual accuracy in Med-LVLM systems. METRAG (Gan et. al. 2024), amulti-layered, thoughts-enhanced retrieval-augmented generation framework, integratesLLMsupervisionto generate utility-oriented thoughts and combines document similarity with utility for improvedperformance. It also incorporates a task-adaptive summarizer to produce compact thoughts. Using themulti-layered thoughts from these stages, an LLM generates knowledge-augmented content,demonstrating superior performance on knowledge-intensive tasks compared to traditional approaches.Distractordocument is'),\n",
       " Document(metadata={'producer': 'Skia/PDF m131 Google Docs Renderer', 'creator': 'PyPDF', 'creationdate': '', 'title': 'A Comprehensive Review of Retrieval-Augmented Generation (RAG): Key Challenges and Future Directions', 'source': 'rag.pdf', 'total_pages': 18, 'page': 8, 'page_label': '9'}, page_content='Figure4: EvolvingTrendsinRAGcapturedfromresearchpapers'),\n",
       " Document(metadata={'producer': 'Skia/PDF m131 Google Docs Renderer', 'creator': 'PyPDF', 'creationdate': '', 'title': 'A Comprehensive Review of Retrieval-Augmented Generation (RAG): Key Challenges and Future Directions', 'source': 'rag.pdf', 'total_pages': 18, 'page': 9, 'page_label': '10'}, page_content=\"one of the key traits of Retrieval AugmentedFine-Tuning(RAFT)(Zhanget. al. 2024)wherethemodel istrained to disregard irrelevant, distractor documents and instead cite directly fromrelevant sources. Thisprocess, combined with a chain-of-thought reasoning style, enhances themodel'sreasoningcapabilities.RAFT demonstrates consistent performance improvements in domain-specific RAG tasks, includingPubMed, HotpotQA, and Gorilla datasets, serving as a post-training enhancement for LLMs. FILCO(Wang et. al. 2023) , a method designed toenhancethequalityof context providedtogenerativemodelsin tasks like open-domain question answering and fact verification, addresses issues of over- orunder-relianceonretrievedpassages, whichcanleadtoproblemssuchashallucinationsinthegeneratedoutputs. The method improves context quality by identifying useful context through lexical andinformation-theoretic approaches and training context filtering models to refine retrieved contexts duringtest time.\"),\n",
       " Document(metadata={'producer': 'Skia/PDF m131 Google Docs Renderer', 'creator': 'PyPDF', 'creationdate': '', 'title': 'A Comprehensive Review of Retrieval-Augmented Generation (RAG): Key Challenges and Future Directions', 'source': 'rag.pdf', 'total_pages': 18, 'page': 9, 'page_label': '10'}, page_content='duringtest time. ReflectionTokenisakeyattributeof Self-reflectiveRetrieval Augmented-Generation(Self-RAG)(Asai et. al. 2023), anovel frameworkdesignedtoimprovethefactual accuracyof largelanguagemodels(LLMs) by combining retrieval with self-reflection. Unlike traditional methodsthat retrieveandincorporatea fixed number of passages, Self-RAGadaptively retrievesrelevant passagesandusesreflectiontokensto evaluate and refine its responses, allowing the model to adjust its behavior according to task-specificneeds and has shown superior performance in open-domain question-answering, reasoning, factverification, and long-formgenerationtasks. Intelligenceandeffectivenessof RAGaredependent alot onthe quality of retrieval and more meta-data understanding of the repository would enhance theeffectiveness of the RAGsystem. Anovel data-centric Retrieval-Augmented Generation (RAG)workflowadvances beyond the traditional retrieve-then-read mode and employs aprepare-then-rewrite-then-retrieve-then-read'),\n",
       " Document(metadata={'producer': 'Skia/PDF m131 Google Docs Renderer', 'creator': 'PyPDF', 'creationdate': '', 'title': 'A Comprehensive Review of Retrieval-Augmented Generation (RAG): Key Challenges and Future Directions', 'source': 'rag.pdf', 'total_pages': 18, 'page': 9, 'page_label': '10'}, page_content='framework, enhancing LLMs by integrating contextuallyrelevant, time-critical, or domain-specific information. Key innovations include generating metadata,synthetic Questions and Answers (QA), and introducing the Meta Knowledge Summary (MKSummary)for clusters of documents (Mombaerts et. al. 2024). A recent paper introduces CommunityKG-RAG(Chang et. al. 2024), a zero-shot framework that integrates community structures within KnowledgeGraphs (KGs) into Retrieval-Augmented Generation (RAG) systems. This approach enhances theaccuracy and contextual relevance of fact-checking by utilizing multi-hop connections within KGs,outperforming traditional methods without requiring additional domain-specific training. The RAPTORmodel (Sarthi et. al. 2024) introduces a hierarchical approach to retrieval-augmented language models,addressing limitations in traditional methods that retrieve only short, contiguous text chunks. RAPTORforms a summary tree to retrieve information at varying abstraction'),\n",
       " Document(metadata={'producer': 'Skia/PDF m131 Google Docs Renderer', 'creator': 'PyPDF', 'creationdate': '', 'title': 'A Comprehensive Review of Retrieval-Augmented Generation (RAG): Key Challenges and Future Directions', 'source': 'rag.pdf', 'total_pages': 18, 'page': 9, 'page_label': '10'}, page_content='varying abstraction levels by recursively embedding,clustering, and summarizing text. Experiments demonstrate RAPTOR’s superior performance, especiallyin question-answering tasks requiring complex reasoning. When paired with GPT-4, RAPTORimprovesaccuracyontheQuALITYbenchmarkby20%.'),\n",
       " Document(metadata={'producer': 'Skia/PDF m131 Google Docs Renderer', 'creator': 'PyPDF', 'creationdate': '', 'title': 'A Comprehensive Review of Retrieval-Augmented Generation (RAG): Key Challenges and Future Directions', 'source': 'rag.pdf', 'total_pages': 18, 'page': 9, 'page_label': '10'}, page_content=\"This advancement in RAGfurtherprovestheutilityof theRAGsystemhoweverrecent LLMlaunchesthatsupport long-termcontext havesignificantlyshownimprovedperformance. Arecent study(Li et. al. 2024)compared the efficiency of Retrieval Augmented Generation (RAG) and long-context (LC) LargeLanguage Models (LLMs), such as Gemini-1.5 and GPT-4. While LC models outperform RAG whenadequately resourced, RAG's cost-efficiency remains advantageous. To balance performance and cost,the paper introduces Self-Route. This method dynamically directs queries to either RAGorLCbasedonmodel self-reflection, optimizing both computation cost and performance. This study offers valuableinsights into the optimal application of RAGand LCin handling long-context tasks. Nguyen et. al., 2024introduce SFR-RAG, a small but highly efficient Retrieval AugmentedGeneration(RAG)model, whichisdesigned to enhance the integration of external contextual information into Large Language Models(LLMs) while minimizing hallucinations.\"),\n",
       " Document(metadata={'producer': 'Skia/PDF m131 Google Docs Renderer', 'creator': 'PyPDF', 'creationdate': '', 'title': 'A Comprehensive Review of Retrieval-Augmented Generation (RAG): Key Challenges and Future Directions', 'source': 'rag.pdf', 'total_pages': 18, 'page': 9, 'page_label': '10'}, page_content='hallucinations. LA-RAG (Li et. al., 2024), a novel Retrieval-AugmentedGeneration (RAG) paradigm designed to enhance Automatic Speech Recognition (ASR) in largelanguage models (LLMs). One of the key benefits of LA-RAG is its ability to leverage fine-grainedtoken-level speech data stores alongside a speech-to-speech retrieval mechanism, improving ASR'),\n",
       " Document(metadata={'producer': 'Skia/PDF m131 Google Docs Renderer', 'creator': 'PyPDF', 'creationdate': '', 'title': 'A Comprehensive Review of Retrieval-Augmented Generation (RAG): Key Challenges and Future Directions', 'source': 'rag.pdf', 'total_pages': 18, 'page': 10, 'page_label': '11'}, page_content='accuracy by incorporating LLMin-context learning (ICL). The studyfocusesondatasetsof Mandarinandvarious Chinese dialects, demonstrating significant accuracy improvements, particularly in managingaccent variations, which have historically been a challenge for existing speech encoders. The findingshighlight LA-RAG’s potential to advance ASR technology, offering a more robust solution for diverseacoustic conditions. Large Language Models (LLMs) face challenges in AI legal and policy contextsdueto outdated knowledge and hallucinations. HyPA-RAG(Kalra et. al., 2024), aHybridParameter-AdaptiveRetrieval-Augmented Generation system, improves accuracy by using adaptive parameter tuning andhybrid retrieval strategies. Tested on NYC Local Law144 (LL144), HyPA-RAGdemonstrates enhancedcorrectness and contextual precision, addressing the complexities of legal texts. MemoRAG(Qianet. al.,2024) introduces a novel Retrieval-Augmented Generation (RAG) paradigmdesigned to overcome thelimitations of'),\n",
       " Document(metadata={'producer': 'Skia/PDF m131 Google Docs Renderer', 'creator': 'PyPDF', 'creationdate': '', 'title': 'A Comprehensive Review of Retrieval-Augmented Generation (RAG): Key Challenges and Future Directions', 'source': 'rag.pdf', 'total_pages': 18, 'page': 10, 'page_label': '11'}, page_content='thelimitations of traditional RAG systems in handling ambiguous or unstructured knowledge. MemoRAG’sdual-system architecture utilizes a lightweight long-range LLM to generate draft answers and guideretrieval tools, while a more powerful LLMrefines the final output. This framework, optimized for bettercluing and memory capacity, significantly outperforms conventional RAG models across both complexand straightforward tasks. NLLB-E5 (Acharya et. al., 2024) introduces a scalable multilingual retrievalmodel aimed at addressing the challenges faced in supporting multiple languages, particularlylow-resource languages like Indiclanguages. ByleveragingtheNLLBencoderandadistillationapproachfromtheE5multilingual retriever, NLLB-E5enableszero-shot retrieval acrosslanguageswithout theneedfor multilingual training data. Evaluations on benchmarks such as Hindi-BEIR showcase its robustperformance, highlighting task-specific challenges and advancing multilingual information access forglobal'),\n",
       " Document(metadata={'producer': 'Skia/PDF m131 Google Docs Renderer', 'creator': 'PyPDF', 'creationdate': '', 'title': 'A Comprehensive Review of Retrieval-Augmented Generation (RAG): Key Challenges and Future Directions', 'source': 'rag.pdf', 'total_pages': 18, 'page': 10, 'page_label': '11'}, page_content='access forglobal inclusivity.'),\n",
       " Document(metadata={'producer': 'Skia/PDF m131 Google Docs Renderer', 'creator': 'PyPDF', 'creationdate': '', 'title': 'A Comprehensive Review of Retrieval-Augmented Generation (RAG): Key Challenges and Future Directions', 'source': 'rag.pdf', 'total_pages': 18, 'page': 10, 'page_label': '11'}, page_content='5. CurrentChallenges andLimitationsinRetrieval-AugmentedGeneration(RAG):\\nThissectionintendstohighlight thecurrent challengesandlimitationsof RAGconsideringthecurrentlandscapeof thesystemandthiswouldshapethefutureresearchdirectionsinthefield.\\nScalability and Efficiency: One of the primary challenges for RAG models is scalability. As retrievalcomponentsrelyonexternal databases, handlingvast anddynamicallygrowingdatasetsrequiresefficientretrieval algorithms. High computational costs and memory requirements also make it difficult to deployRAGmodelsinreal-timeorresource-constrainedenvironments(Shi et al. 2023), (Asai et al. 2023b).'),\n",
       " Document(metadata={'producer': 'Skia/PDF m131 Google Docs Renderer', 'creator': 'PyPDF', 'creationdate': '', 'title': 'A Comprehensive Review of Retrieval-Augmented Generation (RAG): Key Challenges and Future Directions', 'source': 'rag.pdf', 'total_pages': 18, 'page': 10, 'page_label': '11'}, page_content='Retrieval Quality andRelevance: Ensuring the quality andrelevanceof retrieveddocumentsremainsasignificant concern. Retrieval models can sometimes return irrelevant or outdated information, whichnegatively affects the accuracy of the generated output. Improving retrieval precision, especially forlong-formcontent generation, remainsanactiveareaof research(Mallenet al. 2022), (Shi et al. 2023).\\nBias and Fairness: Similar to other machine learning models, RAG systems can exhibit bias due tobiases present in the retrieved datasets. Retrieval-based models may amplifyharmful biasesinretrievedknowledge, leading to biased outputs in a generation. Developing bias mitigation techniquesforretrievalandgenerationintandemisanongoingchallenge.'),\n",
       " Document(metadata={'producer': 'Skia/PDF m131 Google Docs Renderer', 'creator': 'PyPDF', 'creationdate': '', 'title': 'A Comprehensive Review of Retrieval-Augmented Generation (RAG): Key Challenges and Future Directions', 'source': 'rag.pdf', 'total_pages': 18, 'page': 10, 'page_label': '11'}, page_content=\"Coherence: RAG models often struggle with integrating the retrieved knowledge into coherent,contextually relevant text. The alignment between retrieved passages and the generationmodel'soutputis not always seamless, leading to inconsistencies or factual hallucinations in the final response(Ji et al.2022).\"),\n",
       " Document(metadata={'producer': 'Skia/PDF m131 Google Docs Renderer', 'creator': 'PyPDF', 'creationdate': '', 'title': 'A Comprehensive Review of Retrieval-Augmented Generation (RAG): Key Challenges and Future Directions', 'source': 'rag.pdf', 'total_pages': 18, 'page': 11, 'page_label': '12'}, page_content='Interpretability and Transparency: Like many AI systems, RAG models are often treated as blackboxes, with limited transparency in how retrieval influences generation. Improving the interpretability ofthesemodelsiscrucial tofosteringtrust, especiallyincritical applications(Rolleret al. 2020).\\n6. FutureResearchDirectionsforRetrieval-AugmentedGeneration(RAG)\\nRetrieval-augmented generation (RAG) represents a significant advancement in natural languageprocessing and related fields by combining retrieval and generative mechanisms. This section exploreskeyareasforfutureresearch, highlightingthepotential forinnovationandimprovement inRAGsystems.'),\n",
       " Document(metadata={'producer': 'Skia/PDF m131 Google Docs Renderer', 'creator': 'PyPDF', 'creationdate': '', 'title': 'A Comprehensive Review of Retrieval-Augmented Generation (RAG): Key Challenges and Future Directions', 'source': 'rag.pdf', 'total_pages': 18, 'page': 11, 'page_label': '12'}, page_content='6.1 Enhancing Multimodal Integration: The integration of text, image, audio, and video data in RAGmodels remains an evolving challenge. Future research should focus on improving multimodal fusiontechniques to enable seamless interaction between different data types. This includes developingadvanced methods for aligning and synthesizing information across modalities. Recent works (Chen et.al. 2022), (Yasunaga et. al. 2022), (Zhu et. al. 2024) have explored multimodal learning, but furtherinnovations are needed to enhance the coherence andcontextualityof multimodal outputs.Researchintocross-modal retrieval aims to improve the ability of RAGsystems to retrieve relevant information acrossdifferent modalities. For example, combining text-based queries with image or video content retrievalcould enhance applications such as visual question answering and multimedia search. This is anotherfuturedirectiontoexploreforRAGrelatedresearch.'),\n",
       " Document(metadata={'producer': 'Skia/PDF m131 Google Docs Renderer', 'creator': 'PyPDF', 'creationdate': '', 'title': 'A Comprehensive Review of Retrieval-Augmented Generation (RAG): Key Challenges and Future Directions', 'source': 'rag.pdf', 'total_pages': 18, 'page': 11, 'page_label': '12'}, page_content='6.2 Scaling and Efficiency: As RAG models are deployed in increasingly large-scale applications,scalability becomes a critical concern. Research should focus on developing methods toefficientlyscaleretrieval and generation processes without compromising performance. Techniques such as distributedcomputing and efficient indexing methods are essential for handling large datasets. Improving theefficiency of RAG models involves optimizing both retrieval and generation components to reducecomputational resourcesandlatency.'),\n",
       " Document(metadata={'producer': 'Skia/PDF m131 Google Docs Renderer', 'creator': 'PyPDF', 'creationdate': '', 'title': 'A Comprehensive Review of Retrieval-Augmented Generation (RAG): Key Challenges and Future Directions', 'source': 'rag.pdf', 'total_pages': 18, 'page': 11, 'page_label': '12'}, page_content='6.3 Personalization and Adaptation: Future RAG models should focus on personalizing retrievalprocesses to cater to individual user preferences and contexts. This involves developing techniques toadapt retrieval strategies based on user history, behaviour, and preferences. Enhancing the contextualadaptation of RAGmodels by deeper understandingof thecontext andsentimentsof query(Guptaet. al.2024) and the repository of ducments is crucial for improving the relevance of generated responses.Research should explore methods for dynamic adjustment of retrieval and generation processes basedontheevolvingcontext of interactions. Thisincludesincorporatinguserfeedbackandcontextual cuesintotheRAGpipeline.'),\n",
       " Document(metadata={'producer': 'Skia/PDF m131 Google Docs Renderer', 'creator': 'PyPDF', 'creationdate': '', 'title': 'A Comprehensive Review of Retrieval-Augmented Generation (RAG): Key Challenges and Future Directions', 'source': 'rag.pdf', 'total_pages': 18, 'page': 11, 'page_label': '12'}, page_content='6.4 Ethical andPrivacyConsiderations:Addressingbiases(Shresthaet. al. 2024), (Guptaet. al. 2024)in general and specifics to RAG models is a critical area for future research. As RAG systems aredeployed in diverse applications, ensuring fairness and mitigating biases in retrieved and generatedcontent is essential. Future RAG research should focus on privacy-preserving techniques to protectsensitive information during retrieval and generation. This includes developing methods for secure datahandling and privacy-aware retrieval strategies. Interpretability of model is also a critical area to focusuponasapart of ongoingresearchinimprovingRAG.\\n6.5 Cross-Lingual and Low-Resource Languages: Expanding RAG technology to support multiplelanguages ( Chirkova et. al. 2024), especially low-resource languages, is a promising direction. Future'),\n",
       " Document(metadata={'producer': 'Skia/PDF m131 Google Docs Renderer', 'creator': 'PyPDF', 'creationdate': '', 'title': 'A Comprehensive Review of Retrieval-Augmented Generation (RAG): Key Challenges and Future Directions', 'source': 'rag.pdf', 'total_pages': 18, 'page': 12, 'page_label': '13'}, page_content='research should aimtoimprovecross-lingual retrieval andgenerationcapabilitiestoprovideaccurateandrelevant results across different languages. Enhancing RAG models to effectively support low-resourcelanguages involves developing methods to retrieve and generate content with limited training data.Research should focus on techniques for transfer learning and data augmentation to improveperformanceinunderrepresentedlanguages.\\n6.6 Advanced Retrieval Mechanisms: Future RAG research should explore dynamic retrievalmechanisms that adapt to changing query patterns and content requirements. This includes developingmodels that can dynamically update theirretrieval strategiesbasedonnewinformationandevolvinguserneeds. Investigating hybrid retrieval approaches that combine various retrieval strategies, suchasdenseand sparse retrieval, could enhance the effectiveness of RAGsystems. Research shouldexplorehowtointegratedifferent retrieval methodstoachieveoptimal performancefordiversetasks.'),\n",
       " Document(metadata={'producer': 'Skia/PDF m131 Google Docs Renderer', 'creator': 'PyPDF', 'creationdate': '', 'title': 'A Comprehensive Review of Retrieval-Augmented Generation (RAG): Key Challenges and Future Directions', 'source': 'rag.pdf', 'total_pages': 18, 'page': 12, 'page_label': '13'}, page_content='6.7 Integration with Emerging Technologies: Integrating RAGmodels with brain-computer interfaces(BCIs) could lead to novel applications in human-computer interaction and assistive technologies.Research should explore how RAG systems can leverage BCI data to enhance user experience andgenerate context-aware responses.The integration of RAG with AR and VR technologies presentsopportunities for creating immersive and interactive experiences. FutureresearchshouldinvestigatehowRAG models can be used to enhance AR and VR applications by providing contextually relevantinformationandinteractions.\\n7. Conclusion'),\n",
       " Document(metadata={'producer': 'Skia/PDF m131 Google Docs Renderer', 'creator': 'PyPDF', 'creationdate': '', 'title': 'A Comprehensive Review of Retrieval-Augmented Generation (RAG): Key Challenges and Future Directions', 'source': 'rag.pdf', 'total_pages': 18, 'page': 12, 'page_label': '13'}, page_content=\"Retrieval-Augmented Generation (RAG) has undergone significant evolution, with extensive researchdedicated to improving retrieval effectiveness and enhancing coherent generation to minimizehallucinations. Fromitsearlyiterationstorecent advancements, RAGhasbeeninstrumental inintegratingexternal knowledge into Large Language Models (LLMs), thereby boosting accuracy and reliability. Inparticular, recent domain-specific work has showcased RAG's potential in specialized areas such aslegal, medical, and low-resource language applications, highlighting its adaptability andscope. However,despite these advances, this paper identifies clear gaps that remain unresolved. Challengessuchastheintegration of ambiguous or unstructured information, effective handling of domain-specific contexts, andthe high computational overhead of complex retrieval tasks still persist. These limitations constrain thebroader applicability of RAG systems, particularly in diverse and dynamic real-world environments.\"),\n",
       " Document(metadata={'producer': 'Skia/PDF m131 Google Docs Renderer', 'creator': 'PyPDF', 'creationdate': '', 'title': 'A Comprehensive Review of Retrieval-Augmented Generation (RAG): Key Challenges and Future Directions', 'source': 'rag.pdf', 'total_pages': 18, 'page': 12, 'page_label': '13'}, page_content='environments. Thefuture research directions outlined in this paper—ranging from improving retrieval mechanisms toenhancing context management and ensuring scalability—will serveasacritical guideforthenext phaseof innovation in this space. By addressing these gaps, the next generation of RAG models has thepotential to drive more reliable, efficient, and domain-adaptable LLM systems, further pushing theboundariesof what ispossibleinretrieval-augmentedAI applications.'),\n",
       " Document(metadata={'producer': 'Skia/PDF m131 Google Docs Renderer', 'creator': 'PyPDF', 'creationdate': '', 'title': 'A Comprehensive Review of Retrieval-Augmented Generation (RAG): Key Challenges and Future Directions', 'source': 'rag.pdf', 'total_pages': 18, 'page': 13, 'page_label': '14'}, page_content='References:\\nAcharya, A., Murthy, R., Kumar, V., &Sen, J. (2024). NLLB-E5: AScalable Multilingual Retrieval Model.ArXiv. /abs/2409.05401\\nAlayrac, J., Donahue, J., Luc, P., Miech, A., Barr, I., Hasson, Y., Lenc, K., Mensch, A., Millican, K.,Reynolds, M., Ring, R., Rutherford, E., Cabi, S., Han, T., Gong, Z., Samangooei, S., Monteiro, M.,Menick, J., Borgeaud, S., . . . Simonyan, K. (2022). Flamingo: AVisual Language Model for Few-ShotLearning. ArXiv. /abs/2204.14198\\nAsai, A., Wu, Z., Wang, Y., Sil, A., &Hajishirzi, H. (2023). Self-RAG: Learning to retrieve, generate, andcritiquethroughself-reflection. arXivpreprint arXiv:2310.11511.\\nBaevski, A., Zhou, H., Mohamed, A., &Auli, M. (2020). Wav2vec 2.0: AFramework for Self-SupervisedLearningof SpeechRepresentations. ArXiv. /abs/2006.11477\\nBertasius, G., Wang, H., & Torresani, L. (2021). Is Space-Time Attention All You Need for VideoUnderstanding?ArXiv. /abs/2102.05095'),\n",
       " Document(metadata={'producer': 'Skia/PDF m131 Google Docs Renderer', 'creator': 'PyPDF', 'creationdate': '', 'title': 'A Comprehensive Review of Retrieval-Augmented Generation (RAG): Key Challenges and Future Directions', 'source': 'rag.pdf', 'total_pages': 18, 'page': 13, 'page_label': '14'}, page_content='Binns, R. (2018). Fairness in machine learning: Lessons frompolitical philosophy. Proceedings of the2018ConferenceonFairness, Accountability, andTransparency(pp. 149-159).\\nBorgeaud, S., Mensch, A., Hoffmann, J., Cai, T., Rutherford, E., Millican, K., Driessche, G. V., Lespiau, J.,Damoc, B., Clark, A., Casas, D. D., Guy, A., Menick, J., Ring, R., Hennigan, T., Huang, S., Maggiore, L.,Jones, C., Cassirer, A., . . . Sifre, L. (2021). Improving language models by retrieving fromtrillions oftokens. ArXiv. /abs/2112.04426\\nBrown, T., et al. (2020). \"LanguageModelsareFew-Shot Learners.\"arXivpreprint arXiv:2005.14165.\\nChang, R., & Zhang, J. (2024). CommunityKG-RAG: Leveraging Community Structures in KnowledgeGraphsforAdvancedRetrieval-AugmentedGenerationinFact-Checking. ArXiv. /abs/2408.08535'),\n",
       " Document(metadata={'producer': 'Skia/PDF m131 Google Docs Renderer', 'creator': 'PyPDF', 'creationdate': '', 'title': 'A Comprehensive Review of Retrieval-Augmented Generation (RAG): Key Challenges and Future Directions', 'source': 'rag.pdf', 'total_pages': 18, 'page': 13, 'page_label': '14'}, page_content='Chen, D., Fisch, A., Weston, J., & Bordes, A. (2017). Reading Wikipedia to answer open-domainquestions. In Proceedings of the 55th Annual Meeting of the Association for Computational Linguistics(Volume1: LongPapers)(pp. 1870-1879).\\nChen, W., Hu, H., Chen, X., Verga, P., &Cohen, W. W. (2022). MuRAG: Multimodal Retrieval-AugmentedGeneratorforOpenQuestionAnsweringoverImagesandText. ArXiv. /abs/2210.02928\\nChirkova, N., Rau, D., Déjean, H., Formal, T., Clinchant, S., &Nikoulina, V. (2024). Retrieval-augmentedgenerationinmultilingual settings. ArXiv. /abs/2407.01463\\nDai, Z., & Callan, J. (2019). Context-Aware Sentence/Passage Term Importance Estimation For FirstStageRetrieval. ArXiv. /abs/1910.10687'),\n",
       " Document(metadata={'producer': 'Skia/PDF m131 Google Docs Renderer', 'creator': 'PyPDF', 'creationdate': '', 'title': 'A Comprehensive Review of Retrieval-Augmented Generation (RAG): Key Challenges and Future Directions', 'source': 'rag.pdf', 'total_pages': 18, 'page': 13, 'page_label': '14'}, page_content='Devlin, J., Chang, M. W., Lee, K., & Toutanova, K. (2019). BERT: Pre-training of deep bidirectionaltransformers for language understanding. In Proceedings of the 2019 Conference of theNorthAmericanChapter of the Association for Computational Linguistics: Human Language Technologies (pp.4171-4186).'),\n",
       " Document(metadata={'producer': 'Skia/PDF m131 Google Docs Renderer', 'creator': 'PyPDF', 'creationdate': '', 'title': 'A Comprehensive Review of Retrieval-Augmented Generation (RAG): Key Challenges and Future Directions', 'source': 'rag.pdf', 'total_pages': 18, 'page': 14, 'page_label': '15'}, page_content='Devlin, J., Chang, M., Lee, K., & Toutanova, K. (2018). BERT: Pre-training of Deep BidirectionalTransformersforLanguageUnderstanding. ArXiv. /abs/1810.04805\\nGan, C., Yang, D., Hu, B., Zhang, H., Li, S., Liu, Z., Shen, Y., Ju, L., Zhang, Z., Gu, J., Liang, L., &Zhou,J. (2024). Similarity is Not All You Need: Endowing Retrieval Augmented Generation with Multi LayeredThoughts. ArXiv. /abs/2405.19893\\nGatt, A., &Krahmer, &E. (2018). Surveyof thestateof theart innatural languagegeneration: Coretasks,applications, andevaluation. Journal of Artificial IntelligenceResearch, 61, 65-170.\\nGupta, S., &Ranjan, R. (2024). Evaluation of LLMs Biases TowardsEliteUniversities: APersona-BasedExploration. ArXiv. /abs/2407.12801\\nGupta, S., Ranjan, R., & Singh, S. N. (2024). Comprehensive Study on Sentiment Analysis: FromRule-basedtomodernLLMbasedsystem. ArXiv. /abs/2409.09989'),\n",
       " Document(metadata={'producer': 'Skia/PDF m131 Google Docs Renderer', 'creator': 'PyPDF', 'creationdate': '', 'title': 'A Comprehensive Review of Retrieval-Augmented Generation (RAG): Key Challenges and Future Directions', 'source': 'rag.pdf', 'total_pages': 18, 'page': 14, 'page_label': '15'}, page_content='Guu, J., Lee, K., & Pasupat, P. (2020). Retrieval-augmented generation for knowledge-intensive NLPtasks. arXivpreprint. https://arxiv.org/abs/2002.08909\\nGuu, K., Lee, K., Tung, Z., Pasupat, P., & Chang, M. (2020). REALM: Retrieval-augmented languagemodel pre-training. In Proceedings of the 37th International Conference on Machine Learning (pp.3929-3938).\\nHan, S., Pool, J., Tran, J., & Dally, W. J. (2015). Learning both weights and connections for efficientneural network. InAdvancesinNeural InformationProcessingSystems(pp. 1135-1143).\\nIzacard, G., & Grave, E. (2021). Leveraging passage retrieval with generative models for open domainquestion answering. In Proceedings of the 16th Conference of the European Chapter of the AssociationforComputational Linguistics: MainVolume(pp. 874-880).'),\n",
       " Document(metadata={'producer': 'Skia/PDF m131 Google Docs Renderer', 'creator': 'PyPDF', 'creationdate': '', 'title': 'A Comprehensive Review of Retrieval-Augmented Generation (RAG): Key Challenges and Future Directions', 'source': 'rag.pdf', 'total_pages': 18, 'page': 14, 'page_label': '15'}, page_content='Ji, Z., Lee, N., Frieske, R., Yu, T., Su, D., Xu, Y., Ishii, E., Bang, Y., Chen, D., Dai, W., Chan, H. S.,Madotto, A., & Fung, P. (2022). Survey of Hallucination in Natural Language Generation. ArXiv.https://doi.org/10.1145/3571730\\nKalra, R., Wu, Z., Gulley, A., Hilliard, A., Guan, X., Koshiyama, A., &Treleaven, P. (2024). HyPA-RAG: AHybridParameterAdaptiveRetrieval-AugmentedGenerationSystemforAI Legal andPolicyApplications.ArXiv. /abs/2409.09046\\nKarpukhin, V., Oguz, B., Min, S., & Yih, W. (2020). Dense passage retrieval for open-domain questionanswering. arXivpreprint. https://arxiv.org/abs/2004.04906\\nKarpukhin, V., Oguz, B., Min, S., Lewis, P., Wu, L., Edunov, S., Chen, D. & Yih, W. T. (2020). Densepassage retrieval for open-domain question answering. In Proceedings of the 2020 Conference onEmpirical MethodsinNatural LanguageProcessing(EMNLP)(pp. 6769-6781).'),\n",
       " Document(metadata={'producer': 'Skia/PDF m131 Google Docs Renderer', 'creator': 'PyPDF', 'creationdate': '', 'title': 'A Comprehensive Review of Retrieval-Augmented Generation (RAG): Key Challenges and Future Directions', 'source': 'rag.pdf', 'total_pages': 18, 'page': 14, 'page_label': '15'}, page_content='Lewis, P., Perez, E., Piktus, A., Petroni, F., Karpukhin, V., Goyal, N., ... & Riedel, S. (2020).Retrieval-augmented generation for knowledge-intensive NLP tasks. In Proceedings of the 34thInternational ConferenceonNeural InformationProcessingSystem(pp. 9459-9474).'),\n",
       " Document(metadata={'producer': 'Skia/PDF m131 Google Docs Renderer', 'creator': 'PyPDF', 'creationdate': '', 'title': 'A Comprehensive Review of Retrieval-Augmented Generation (RAG): Key Challenges and Future Directions', 'source': 'rag.pdf', 'total_pages': 18, 'page': 15, 'page_label': '16'}, page_content='Li, C., Liu, Z., Xiao, S., & Shao, Y. (2023). Making Large Language Models A Better Foundation ForDenseRetrieval. ArXiv. /abs/2312.15503\\nLi, F., Zhu, L., Wang, T., Li, J., Zhang, Z., & Shen, H. T. (2023). Cross-Modal Retrieval: ASystematicReviewof MethodsandFutureDirections. ArXiv. /abs/2308.14263\\nLi, S., Shang, H., Wei, D., Guo, J., Li, Z., He, X., Zhang, M., & Yang, H. (2024). LA-RAG:EnhancingLLM-basedASRAccuracywithRetrieval-AugmentedGeneration. ArXiv. /abs/2409.08597\\nLi, S., Park, S., Lee, I., & Bastani, O. (2023). TRAQ: Trustworthy Retrieval Augmented QuestionAnsweringviaConformal Prediction. ArXiv. /abs/2307.04642\\nLi, Z., Li, C., Zhang, M., Mei, Q., & Bendersky, M. (2024). Retrieval Augmented Generation orLong-Context LLMs?AComprehensiveStudyandHybridApproach. ArXiv. /abs/2407.16833\\nLiu, Z., Wang, H., Niu, Z., Wu, H., Che, W., &Liu, T. (2020). Towards Conversational RecommendationoverMulti-TypeDialogs. ArXiv. /abs/2005.03954'),\n",
       " Document(metadata={'producer': 'Skia/PDF m131 Google Docs Renderer', 'creator': 'PyPDF', 'creationdate': '', 'title': 'A Comprehensive Review of Retrieval-Augmented Generation (RAG): Key Challenges and Future Directions', 'source': 'rag.pdf', 'total_pages': 18, 'page': 15, 'page_label': '16'}, page_content='Mallen, A., Asai, A., Zhong, V., Das, R., Khashabi, D., & Hajishirzi, H. (2022). When Not to TrustLanguage Models: Investigating Effectiveness of Parametric and Non-Parametric Memories. ArXiv./abs/2212.10511\\nMombaerts, L., Ding, T., Banerjee, A., Felice, F., Taws, J., &Borogovac, T. (2024). Meta Knowledge forRetrieval AugmentedLargeLanguageModels. ArXiv. /abs/2408.09017\\nNguyen, X., Pandit, S., Purushwalkam, S., Xu, A., Chen, H., Ming, Y., Ke, Z., Savarese, S., Xong, C., &Joty, S. (2024). SFR-RAG: TowardsContextuallyFaithful LLMs. ArXiv. /abs/2409.09916\\nNiu, C., Wu, Y., Zhu, J., Xu, S., Shum, K., Zhong, R., Song, J., & Zhang, T. (2023). RAGTruth: AHallucination Corpus for Developing Trustworthy Retrieval-Augmented Language Models. ArXiv./abs/2401.00396\\nQian, H., Zhang, P., Liu, Z., Mao, K., &Dou, Z. (2024). MemoRAG: Moving towards Next-Gen RAGViaMemory-InspiredKnowledgeDiscovery. ArXiv. /abs/2409.05591'),\n",
       " Document(metadata={'producer': 'Skia/PDF m131 Google Docs Renderer', 'creator': 'PyPDF', 'creationdate': '', 'title': 'A Comprehensive Review of Retrieval-Augmented Generation (RAG): Key Challenges and Future Directions', 'source': 'rag.pdf', 'total_pages': 18, 'page': 15, 'page_label': '16'}, page_content='Radford, A., Wu, J., Child, R., Luan, D., Amodei, D., & Sutskever, I. (2019). Language models areunsupervisedmultitasklearners. OpenAI Blog, 1(8), 9.\\nRaffel, C., Shazeer, N., Roberts, A., Lee, K., Narang, S., Matena, M., Zhou, Y., Li, W., &Liu, P. J. (2019).ExploringtheLimitsof TransferLearningwithaUnifiedText-to-Text Transformer. ArXiv. /abs/1910.10683\\nRanade, P., & Joshi, A. (2023). FABULA: Intelligence Report Generation Using Retrieval-AugmentedNarrativeConstruction. ArXiv. https://doi.org/10.1145/3625007.3627505\\nRanjan, R., Gupta, S., & Singh, S. N. (2024). A Comprehensive Survey of Bias in LLMs: CurrentLandscapeandFutureDirections. ArXiv. /abs/2409.16430\\nRavuru, C., Sakhinana, S. S., &Runkana, V. (2024). Agentic Retrieval-Augmented Generation for TimeSeriesAnalysis. ArXiv. /abs/2408.14484'),\n",
       " Document(metadata={'producer': 'Skia/PDF m131 Google Docs Renderer', 'creator': 'PyPDF', 'creationdate': '', 'title': 'A Comprehensive Review of Retrieval-Augmented Generation (RAG): Key Challenges and Future Directions', 'source': 'rag.pdf', 'total_pages': 18, 'page': 16, 'page_label': '17'}, page_content='Robertson, S.G., & Zaragoza,H., (2009). The Probabilistic Relevance Framework: BM25 and Beyond,FoundationsandTrendsinInformationRetrieval, 3(4), pp. 333-389.\\nRoller, S., Dinan, E., Goyal, N., Ju, D., Williamson, M., Liu, Y., Xu, J., Ott, M., Shuster, K., Smith, E. M.,Boureau, Y., &Weston, J. (2020). Recipesforbuildinganopen-domainchatbot. ArXiv. /abs/2004.13637\\nSalton, G., Wong, A., & Yang, C. S. (1975). A vector space model for automatic indexing.Communicationsof theACM, 18(11), 613-620.\\nSanh, V., Debut, L., Chaumond, J., & Wolf, T. (2019). DistilBERT, a distilled version of BERT: Smaller,faster, cheaperandlighter. ArXiv. /abs/1910.01108\\nSarthi, P., Abdullah, S., Tuli, A., Khanna, S., Goldie, A., &Manning, C. D. (2024). RAPTOR: RecursiveAbstractiveProcessingforTree-OrganizedRetrieval. ArXiv. /abs/2401.18059'),\n",
       " Document(metadata={'producer': 'Skia/PDF m131 Google Docs Renderer', 'creator': 'PyPDF', 'creationdate': '', 'title': 'A Comprehensive Review of Retrieval-Augmented Generation (RAG): Key Challenges and Future Directions', 'source': 'rag.pdf', 'total_pages': 18, 'page': 16, 'page_label': '17'}, page_content=\"Shi, W., Min, S., Yasunaga, M., Seo, M., James, R., Lewis, M., Zettlemoyer, L., & Yih, W.-T. (2023).REPLUG: Retrieval-augmentedblack-boxlanguagemodels. arXivpreprint arXiv:2301.12652.\\nShrestha, R., Zou, Y., Chen, Q., Li, Z., Xie, Y., &Deng, S. (2024). FairRAG: Fair Human GenerationviaFairRetrieval Augmentation. ArXiv. /abs/2403.19964\\nSutskever, I., Vinyals, O., & Le, Q. V. (2014). Sequence to sequence learning with neural networks. InAdvancesinNeural InformationProcessingSystems(pp. 3104-3112).\\nThakur, N., Bonifacio, L., Zhang, X., Ogundepo, O., Kamalloo, E., Li, X., Liu, Q., Chen, B.,Rezagholizadeh, M., &Lin, J. (2023). NoMIRACL: KnowingWhenYouDon't KnowforRobust MultilingualRetrieval-AugmentedGeneration. ArXiv. /abs/2312.11361\\nThakur, N., Reimers, N., Ruckl'e, A., Srivastava, A., & Gurevych, I. (2021). BEIR: A HeterogenousBenchmarkforZero-shot Evaluationof InformationRetrieval Models. ArXiv, abs/2104.08663.\"),\n",
       " Document(metadata={'producer': 'Skia/PDF m131 Google Docs Renderer', 'creator': 'PyPDF', 'creationdate': '', 'title': 'A Comprehensive Review of Retrieval-Augmented Generation (RAG): Key Challenges and Future Directions', 'source': 'rag.pdf', 'total_pages': 18, 'page': 16, 'page_label': '17'}, page_content='Vaswani, A., Shazeer, N., Parmar, N., Uszkoreit, J., Jones, L., Gomez, A. N., Kaiser, Ł., &Polosukhin, I.(2017). Attentionisall youneed. InAdvancesinNeural InformationProcessingSystems(pp. 5998-6008).\\nWang, X., Wang, Z., Gao, X., Zhang, F., Wu, Y., Xu, Z., Shi, T., Wang, Z., Li, S., Qian, Q., Yin, R., Lv, C.,Zheng, X., &Huang, X. (2024). Searching for Best Practices in Retrieval-Augmented Generation. ArXiv./abs/2407.01219\\nWang, Z., Araki, J., Jiang, Z., Parvez, M. R., & Neubig, G. (2023). Learning to Filter Context forRetrieval-AugmentedGeneration. ArXiv. /abs/2311.08377\\nXia, P., Zhu, K., Li, H., Zhu, H., Li, Y., Li, G., Zhang, L., &Yao, H. (2024). RULE: ReliableMultimodal RAGforFactualityinMedical VisionLanguageModels. ArXiv. /abs/2407.05131\\nXie, S., Sun, C., Huang, J., Tu, Z., & Murphy, K. (2017). Rethinking Spatiotemporal Feature Learning:Speed-AccuracyTrade-offsinVideoClassification. ArXiv. /abs/1712.04851'),\n",
       " Document(metadata={'producer': 'Skia/PDF m131 Google Docs Renderer', 'creator': 'PyPDF', 'creationdate': '', 'title': 'A Comprehensive Review of Retrieval-Augmented Generation (RAG): Key Challenges and Future Directions', 'source': 'rag.pdf', 'total_pages': 18, 'page': 16, 'page_label': '17'}, page_content='Xiong, L., Xiong, C., Li, Y., Tang, K., Liu, J., Bennett, P., Ahmed, J., &Overwijk, A. (2020). ApproximateNearest NeighborNegativeContrastiveLearningforDenseText Retrieval. ArXiv. /abs/2007.00808'),\n",
       " Document(metadata={'producer': 'Skia/PDF m131 Google Docs Renderer', 'creator': 'PyPDF', 'creationdate': '', 'title': 'A Comprehensive Review of Retrieval-Augmented Generation (RAG): Key Challenges and Future Directions', 'source': 'rag.pdf', 'total_pages': 18, 'page': 17, 'page_label': '18'}, page_content='Yasunaga, M., Aghajanyan, A., Shi, W., James, R., Leskovec, J., Liang, P., Lewis, M., Zettlemoyer, L., &Yih, W. (2022). Retrieval-AugmentedMultimodal LanguageModeling. ArXiv. /abs/2211.12561\\nZhang, T., Patil, S. G., Jain, N., Shen, S., Zaharia, M., Stoica, I., & Gonzalez, J. E. (2024). RAFT:AdaptingLanguageModel toDomainSpecificRAG. ArXiv. /abs/2403.10131\\nZhu, Y., Ren, C., Xie, S., Liu, S., Ji, H., Wang, Z., Sun, T., He, L., Li, Z., Zhu, X., & Pan, C. (2024).REALM: RAG-Driven Enhancement of Multimodal Electronic Health Records Analysis via LargeLanguageModels. ArXiv. /abs/2402.07016')]"
      ]
     },
     "execution_count": 114,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "docs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "id": "25505a4e-555f-46f1-962a-0471ac777956",
   "metadata": {},
   "outputs": [],
   "source": [
    "# import weaviate\n",
    "\n",
    "\n",
    "# vector_db = Weaviate.afrom_documents(\n",
    "#     docs,embedding,client=client,by_text=False\n",
    "# )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "id": "6778da26-2c7b-4c52-9e37-a8d39697c5be",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_core.vectorstores import InMemoryVectorStore\n",
    "# vector_store = InMemoryVectorStore(embedding=embedding)\n",
    "vector_store = InMemoryVectorStore.from_documents(docs, embedding)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 149,
   "id": "63611726-42dd-446e-8fb1-4a760a3d592e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"The retriever in RAG systems is essential for fetching relevant documents from an external corpus.Effective retrieval ensures that the model's output is grounded in accurate information. Several retrievalmechanisms are commonly used, ranging from traditional methods like BM25 to more sophisticatedtechniqueslikeDensePassageRetrieval (DPR).\""
      ]
     },
     "execution_count": 149,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vector_store.similarity_search(\"what are rag systems ?\",k=2)[0].page_content"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 151,
   "id": "acaa062d-de50-41f2-8393-aab3175d79c6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'6.2 Scaling and Efficiency: As RAG models are deployed in increasingly large-scale applications,scalability becomes a critical concern. Research should focus on developing methods toefficientlyscaleretrieval and generation processes without compromising performance. Techniques such as distributedcomputing and efficient indexing methods are essential for handling large datasets. Improving theefficiency of RAG models involves optimizing both retrieval and generation components to reducecomputational resourcesandlatency.'"
      ]
     },
     "execution_count": 151,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vector_store.similarity_search(\"what are rag systems ?\",k=2)[1].page_content"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 156,
   "id": "c8cd9382-805c-4965-b49b-95b90ead403e",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.prompts import ChatPromptTemplate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 160,
   "id": "8af47997-44dd-470f-90e0-45d9dcbabc81",
   "metadata": {},
   "outputs": [],
   "source": [
    "template = \"\"\" You are an assistance for question Answering Task.\n",
    "                Use the following pieces of retrieved context to answer the question.\n",
    "                If you dont' know the answer ,just say that you dont know.\n",
    "                use ten sentence maximum and keep the answer concise.\n",
    "                Question: {question}\n",
    "                Context : {context}\n",
    "                Answer:\n",
    "                \"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 162,
   "id": "1c8c039a-0a43-46e4-8add-7c866e8df7b1",
   "metadata": {},
   "outputs": [],
   "source": [
    "prompt=ChatPromptTemplate.from_template(template)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 164,
   "id": "ae2c6cd5-067d-44aa-8c83-a7b64df88100",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ChatPromptTemplate(input_variables=['context', 'question'], input_types={}, partial_variables={}, messages=[HumanMessagePromptTemplate(prompt=PromptTemplate(input_variables=['context', 'question'], input_types={}, partial_variables={}, template=\" You are an assistance for question Answering Task.\\n                Use the following pieces of retrieved context to answer the question.\\n                If you dont' know the answer ,just say that you dont know.\\n                use ten sentence maximum and keep the answer concise.\\n                Question: {question}\\n                Context : {context}\\n                Answer:\\n                \"), additional_kwargs={})])"
      ]
     },
     "execution_count": 164,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "prompt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 202,
   "id": "14431ffa-dd08-48b6-9b64-7fa1cf62f07d",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain import HuggingFaceHub"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 260,
   "id": "3a523007-ac27-47c5-bfe5-ee3ec0596ecf",
   "metadata": {},
   "outputs": [],
   "source": [
    "# from langchain_community.llms import HuggingFaceEndpoint\n",
    "\n",
    "# model = HuggingFaceEndpoint(\n",
    "#     repo_id=\"tiiuae/falcon-7b-instruct\",\n",
    "#     huggingfacehub_api_token=\"BcLTA7waWMTRJj3lE2IN6oucjiATjnRd\",  # Replace with your actual token\n",
    "#     task=\"text-generation\",\n",
    "#     temperature=0.7,\n",
    "#     max_new_tokens=200,\n",
    "#     top_p=0.95\n",
    "# )\n",
    "\n",
    "# # Test generation\n",
    "# response = model.invoke(\"What is quantum computing in simple terms?\")\n",
    "# print(response)\n",
    "\n",
    "# from langchain_community.llms import HuggingFaceEndpoint\n",
    "# import os\n",
    "# model = HuggingFaceEndpoint(\n",
    "#     repo_id=\"mistralai/Mistral-7B-Instruct-v0.2\", \n",
    "#     huggingfacehub_api_token=\"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\", \n",
    "#     task=\"text-generation\",\n",
    "#     temperature=0.7,\n",
    "#     max_new_tokens=200,\n",
    "#     top_p=0.95\n",
    "# )\n",
    "\n",
    "# response = model.invoke(\"What is quantum computing in simple terms?\")\n",
    "# print(response)\n",
    "\n",
    "\n",
    "# from huggingface_hub import InferenceClient\n",
    "\n",
    "# client = InferenceClient(\n",
    "#     model=\"HuggingFaceH4/zephyr-7b-beta\",  # or your preferred model\n",
    "#     token=\"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\"          # DO NOT expose this in public code\n",
    "# )\n",
    "\n",
    "# model = client.text_generation(\n",
    "#     prompt=\"What is quantum computing in simple terms?\",\n",
    "#     max_new_tokens=200,\n",
    "#     temperature=0.7,\n",
    "#     top_p=0.95\n",
    "# )\n",
    "\n",
    "# print(response)\n",
    "from langchain_core.language_models.llms import LLM\n",
    "from pydantic import PrivateAttr\n",
    "\n",
    "class HFInferenceLLM(LLM):\n",
    "    _client: InferenceClient = PrivateAttr()\n",
    "    _gen_params: dict = PrivateAttr()\n",
    "\n",
    "    def __init__(self, client: InferenceClient, **gen_params):\n",
    "        super().__init__()\n",
    "        self._client = client\n",
    "        self._gen_params = gen_params\n",
    "\n",
    "    def _call(self, prompt: str, stop=None, **kwargs) -> str:\n",
    "        return self._client.text_generation(prompt=prompt, **self._gen_params).strip()\n",
    "\n",
    "    @property\n",
    "    def _llm_type(self) -> str:\n",
    "        return \"hf_inference_client\"\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "from huggingface_hub import InferenceClient\n",
    "\n",
    "hf_client = InferenceClient(\n",
    "    model=\"HuggingFaceH4/zephyr-7b-beta\",\n",
    "    token=\"**********************************\"\n",
    ")\n",
    "\n",
    "model = HFInferenceLLM(\n",
    "    client=hf_client,\n",
    "    max_new_tokens=200,\n",
    "    temperature=0.7,\n",
    "    top_p=0.95\n",
    ")\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 262,
   "id": "0834dbd3-c099-4e73-b856-cee2bb31709e",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.schema.runnable import RunnablePassthrough\n",
    "from langchain.schema.output_parser import StrOutputParser\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 264,
   "id": "afcd2fe2-49d7-48e2-9940-27479e69dfd8",
   "metadata": {},
   "outputs": [],
   "source": [
    "output_parser = StrOutputParser()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 270,
   "id": "78d17eb4-ba86-4f30-97de-48eabd2f6cc2",
   "metadata": {},
   "outputs": [],
   "source": [
    "retriever = vector_store.as_retriever()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 278,
   "id": "d6dfa0f9-f189-47a6-806d-87a215393de5",
   "metadata": {},
   "outputs": [],
   "source": [
    "rag_chain = (\n",
    "    {\"context\":retriever, \"question\":RunnablePassthrough()}\n",
    "    | prompt\n",
    "    | model\n",
    "    | output_parser\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 284,
   "id": "0322cf4d-5462-43ed-8304-5f5be6ec2596",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<|assistant|>\n",
      "AI, or artificial intelligence, is a technology that allows computers to perform tasks that typically require human intelligence, such as learning, reasoning, and decision-making. One specific application of AI is Retrieval-Augmented Generation (RAG), which combines information retrieval and natural language generation to produce more accurate and informative responses. RAG has enhanced the capabilities of dialogue systems, medical diagnosis systems, legal advisory systems, and personalized recommendation systems by ensuring that responses are both coherent and grounded in factual information. However, challenges and limitations of RAG include the computational overhead of dual processes, the risk of biases, and the need for techniques such as model pruning and knowledge distillation to reduce the computational burden without sacrificing performance.\n"
     ]
    }
   ],
   "source": [
    "print(rag_chain.invoke(\"what is AI ?\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7a369d49-1f20-45da-b9ed-f7094e7e7405",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
